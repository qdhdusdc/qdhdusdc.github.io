<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>因果推断</title>
    <link href="/2023/09/10/%E5%9B%A0%E6%9E%9C%E6%8E%A8%E6%96%AD/"/>
    <url>/2023/09/10/%E5%9B%A0%E6%9E%9C%E6%8E%A8%E6%96%AD/</url>
    
    <content type="html"><![CDATA[<hr><span id="more"></span><h1 id="基本公式">基本公式</h1><p>用大写字母表示随机变量，小写字母代表随机变量的取值，公式中出现的<span class="math inline">\(P(X)\)</span>表示对<span class="math inline">\(X\)</span>的所有取值均成立，<span class="math inline">\(P(X=x)或\)</span><span class="math inline">\(P(x)\)</span>表示<span class="math inline">\(X=x\)</span>的概率。</p><h2 id="条件独立">条件独立</h2><p>在随机变量<span class="math inline">\(C\)</span>的取值确定的情况下<span class="math inline">\((C=k)\)</span>，随机变量<span class="math inline">\(A\)</span>与<span class="math inline">\(B\)</span>独立，则<span class="math inline">\(A\)</span>, <span class="math inline">\(B\)</span>关于<span class="math inline">\(C=k\)</span>条件独立，即：</p><p><span class="math inline">\(A\perp B|C=k\iffP(A|C=k)P(B|C=k)=P(AB|C=k)\)</span></p><p>若对任意<span class="math inline">\(C\)</span>的取值均有上述关系，则<span class="math inline">\(A\)</span>, <span class="math inline">\(B\)</span>关于<span class="math inline">\(C\)</span>条件独立，记为<span class="math inline">\(A\perp B|C\)</span></p><p><span class="math inline">\(A\)</span>, <span class="math inline">\(B\)</span>关于<span class="math inline">\(C\)</span>条件独立与<span class="math inline">\(A\)</span>, <span class="math inline">\(B\)</span>独立既不充分也不必要，比如设<span class="math inline">\(A\)</span>：第一次扔硬币正面朝上，<span class="math inline">\(B\)</span>：第二次扔硬币正面朝上，<span class="math inline">\(C\)</span>：两次均正面朝上。此时<span class="math inline">\(A\)</span>与<span class="math inline">\(B\)</span>独立，但是<span class="math inline">\(P(A|C=1)=P(B|C=1)=P(AB|C=1)=1\)</span>，<span class="math inline">\(A\)</span>，<span class="math inline">\(B\)</span>关于<span class="math inline">\(C\)</span>不独立。另一方面，设<span class="math inline">\(A=B=C\)</span>，此时有<span class="math inline">\(P(A|C)P(B|C)=P(AB|C)=1\)</span>，但<span class="math inline">\(P(A)P(B)=P(A)^2\neq P(AB)=P(A)\)</span></p><h2 id="链式法则">链式法则</h2><p>对于随机变量<span class="math inline">\(X_1,X_2...X_n\)</span>，当它们的取值为<span class="math inline">\(X_i=x_i\)</span>时，有 <span class="math display">\[P(x_1,x_2,...x_n)=P(x_1)P(x_2|x_1)...P(x_n|x_1,x_2...x_{n-1})\]</span> 由条件概率定义即可证</p><h1 id="朴素贝叶斯">朴素贝叶斯</h1><p>将分类任务看作是在给定特征的条件下目标取某个值的概率，最终要得到<span class="math inline">\(P(Y|X_1,X_2,...X_n)\)</span></p><p>由条件概率关系（贝叶斯公式） <span class="math display">\[P(Y|X_1,X_2,...X_n)=\frac{P(X_1,X_2,...X_n|Y)P(Y)}{P(X_1,X_2,...X_n)}\]</span> 其中，<span class="math inline">\(P(Y)\)</span>可以由目标取某值的频率得到，在分类任务中，一般目标值的种类数远小于样本数，因此可以这么做。而<span class="math inline">\(P(X_1,X_2,...X_n|Y)\)</span>和<span class="math inline">\(P(X_1,X_2,...X_n)\)</span>就不能这样了，这时特征的组合过多，设想每个特征都是二值的，那么就有<span class="math inline">\(2^n\)</span>种组合，未必找得到符合这种组合的样本。因此，需要做亿点简化，把特征均看作独立的，并且特征关于目标也都是独立的。于是把上式简化成<span class="math display">\[P(Y|X_1,X_2,...X_n)=\frac{P(X_1|Y)P(X_2|Y)...P(X_n|Y)P(Y)}{P(X_1)P(X_2)...P(X_n)}\]</span> 这样<span class="math inline">\(P(X_k|Y)\)</span>，<span class="math inline">\(P(X_k)\)</span>都可以用频率得到了。</p><p>毫无疑问，这种做法过于暴殄天物，数据集特征越多，特征冗余就越多，最后效果越不好。</p><h1 id="贝叶斯网络">贝叶斯网络</h1><p>朴素贝叶斯的做法把特征间的关系完全忽略了。贝叶斯网络则没有这么暴力，虽然还是做了一些简化。需要指出，贝叶斯网络本质上是描述随机变量相关性的关系图，贝叶斯网络中的箭头方向仅代表了特征的加入顺序，箭头连接的两个变量是相关的，但不一定具有因果性。</p><p>贝叶斯网络的算法流程如下：</p><p>输入：随机变量<span class="math inline">\(V_1,V_2...V_n\)</span>输出：描述随机变量相关性的有向无环图DAG</p><ol type="1"><li><p>for <span class="math inline">\(i\)</span> in <span class="math inline">\(1,2...n\)</span> do</p></li><li><p>Add <span class="math inline">\(V_i\)</span> into the graph, if<span class="math inline">\(V_i\)</span> has correlation with any othernodes(which have a smaller order than <span class="math inline">\(V_i\)</span>) in the graph, add a directed edgebetween these two nodes with <span class="math inline">\(V_i\)</span> asthe end point. For example, if <span class="math inline">\(V_k(k&lt;i)\)</span> has a correlation with <span class="math inline">\(V_i\)</span>, then add a directed edge from <span class="math inline">\(V_k\)</span> to <span class="math inline">\(V_i\)</span></p></li><li><p>endfor</p></li><li><p>Compute the probability table for every point.</p></li></ol><h2 id="条件独立假设">条件独立假设</h2><p>可以看到，在贝叶斯网络中的相关性是手动添加的，手动的好处是让网络结构更简单。用启发式算法暴力寻优也可以得到一个贝叶斯网络，能这样做的原因是在贝叶斯网络中只考虑变量之间的相关性，而相关性可以直接由频率给出。例如下图：</p><p><img src="捕获.png">{:width="300px" height="200px"}</p><p>左右两图描述了同一件事，即最右边的概率表。最右边的概率表直接从数据集中得出。这两个结构孰是孰非，站在上帝视角来看是左边描述了正确的因果关系。然而，我们实际上从数据集中只得能得到概率表，也就只能判断出下雨和交通堵塞存在相关性。如何得到因果性会在下文讨论，在此先弄明白另一个问题。考虑一个<span class="math inline">\(n\)</span>个变量组成的贝叶斯网络，若要计算<span class="math inline">\(P(V_k=v_k)\)</span>，则由链式法则计算： <span class="math display">\[P(v_k)=\prod _{i=1}^{n}P(v|)\]</span></p><p>有向图中的节点代表随机变量，有向边代表变量之间的因果关系。</p><p>d分离关系用于判断两个变量之间是否在给定其他变量情况下相互独立。</p><p>命题1：稀疏d</p><p>假设变量服从</p><p>Blocking stands for</p>]]></content>
    
    
    <categories>
      
      <category>ML</category>
      
      <category>Casual Inference</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Machine Learning</tag>
      
      <tag>Casual Inference</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MIMIC IV查询程序</title>
    <link href="/2023/07/08/MIMIC-IV-Script/"/>
    <url>/2023/07/08/MIMIC-IV-Script/</url>
    
    <content type="html"><![CDATA[<hr><h2 id="简介">简介</h2><p>​ 两个python程序用于查询MIMICIV数据库的列，目标地址：https://mimic.mit.edu/docs/iv/modules/</p><h2 id="直接查询">直接查询</h2><p>​运行<code>search.py</code>，直接输入所需查询列名，如果列名存在，返回该表所在地址。该程序需要每次将列名与官方文档所有页面源码匹配，比较慢。</p><h2 id="本地连接postgre查询">本地连接postgre查询</h2><p>​ 为了快速查询，若本地有MIMICIV数据库且连接到postgre，使用以下方法直接生成列名的csv查询：</p><ol type="1"><li>保存列名到csv</li></ol><p>​ 将<code>data.py</code>中数据库的配置修改为本机配置，如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> psycopg2<br>conn = psycopg2.connect(database=<span class="hljs-string">&quot;mimiciv&quot;</span>, user=<span class="hljs-string">&quot;postgres&quot;</span>, password=<span class="hljs-string">&quot;1234&quot;</span>, host=<span class="hljs-string">&quot;localhost&quot;</span>, port=<span class="hljs-string">&quot;5432&quot;</span>)<br></code></pre></td></tr></table></figure><p>然后运行该程序，生成<code>'data/mimiciv_columns.csv</code>文件。该文件存储了全部列名与对应的模式名与表名，前5列如下所示：</p><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs mipsasm">mimiciv_hospadmissions<span class="hljs-keyword">subject_id</span><br><span class="hljs-keyword"></span>mimiciv_hospadmissionshadm_id<br>mimiciv_hospadmissionsadmittime<br>mimiciv_hospadmissions<span class="hljs-keyword">dischtime</span><br><span class="hljs-keyword"></span>mimiciv_hospadmissionsdeathtime<br></code></pre></td></tr></table></figure><ol start="2" type="1"><li>通过读取csv查询</li></ol><p>运行<code>search_based_postgre.py</code>，直接输入所需查询列名，如果列名存在，返回该表所在地址。</p>]]></content>
    
    
    <categories>
      
      <category>Script</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Script</tag>
      
      <tag>MIMIC IV</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>傅里叶变换</title>
    <link href="/2023/07/08/%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2/"/>
    <url>/2023/07/08/%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2/</url>
    
    <content type="html"><![CDATA[<hr><h1 id="傅里叶变换">傅里叶变换</h1><p>​任意函数可以表示为一系列三角函数的和。通过傅里叶变换找出这些三角函数。实际应用上，即使不知道函数的表达式，也可以通过傅里叶变换将其转换为频率函数，以获取原函数的性质。</p><span id="more"></span><h2 id="正交函数系">正交函数系</h2><p><span class="math display">\[\forall i,j\in N,s.t.\int_{a}^{b} f_i(x)f_j(x)dx=\left\{\begin{array}{l}0,\quad i\neq j \\1,\quad i=j \\\end{array}\right.\]</span></p><p>则所有<span class="math inline">\(f_i(x)\)</span>构成正交函数系。</p><p>结论：在一定区间<span class="math inline">\((a,b)\)</span>上，正交函数系可以表出任意函数。根据这个结论，可以将任意函数转换为许多带系数正交函数的和，即：<span class="math display">\[\forall f(x),\exists{a_k},f_{m_k}(x),s.t.f(x)=\sum_{k=1}^{n}a_kf_{m_k}(x)\]</span> 那么，对于具体的<span class="math inline">\(f(x)\)</span>，是否可以找出这些<span class="math inline">\(a_k\)</span>和<span class="math inline">\(f_{m_k}(x)\)</span>?这就是傅里叶变换要做的事。</p><p>上述结论证明：</p><p>希望找到一组<span class="math inline">\(a_k,f_{m_k}(x)\)</span>，使得<span class="math inline">\(f(x)=\sum_{k=1}^{n}a_kf_{m_k}(x)\)</span>，因此，考虑其中一个正交函数<span class="math inline">\(f_{m_n}(x)\)</span>，令<span class="math inline">\(f^{(1)}(x)=f(x)-a_nf_{m_n}(x)\)</span>，如果能证明<span class="math display">\[\int_{a}^{b} [f^{(1)}(x)]^2dx&lt;\int_{a}^{b} [f(x)]^2dx\tag{1}\]</span> 则说明<span class="math inline">\(f^{(1)}(x)\)</span>比<span class="math inline">\(f(x)\)</span>更贴近x轴。同样的，可以证明 <span class="math display">\[0=\int_{a}^{b} [f^{(n)}(x)]^2dx&lt;...&lt;\int_{a}^{b}[f^{(1)}(x)]^2dx&lt;\int_{a}^{b} [f(x)]^2dx\tag{2}\]</span>即原函数每次减去某个正交函数后，都会得到一个更贴近x轴的函数，直到缩减到0.而<span class="math display">\[\begin{aligned}&amp;\int_{a}^{b} [f^{(1)}(x)]^2dx&lt;\int_{a}^{b} [f(x)]^2dx\\&amp;\Leftarrow \int_{a}^{b} [f(x)]^2dx-\int_{a}^{b}2a_nf(x)f_{m_n}(x)dx+\int_{a}^{b} [a_nf_{m_n}(x)]^2dx&lt;\int_{a}^{b}[f(x)]^2dx\\&amp;\Leftarrow a_n&lt;\int_{a}^{b} 2f(x)f_{m_n}(x)dx\end{aligned}\]</span> 由于<span class="math inline">\(a_n\)</span>为常数，于是必定存在满足条件的<span class="math inline">\(a_n\)</span>，使得式(1)能成立，同理可证明式(2).</p><p>在傅里叶变换中用三角函数系 <span class="math display">\[\{ sinmx,cosmx|m\in N\}\]</span> 容易证明三角函数系满足正交函数系的条件.</p><h2 id="傅里叶级数">傅里叶级数</h2><p>​由上一节的结论，可知在一定区间上，正交函数系可以表出任意函数。选用三角函数系的原因在于便于找出这些正交函数的系数。换句话说，正交函数系是无穷多的，我们只用便于计算的。傅里叶级数就是把任意函数表示成确定系数的三角函数的和。</p><p>任意函数<span class="math inline">\(f(x)\)</span>用三角函数系表示为：<span class="math display">\[f(x)=\sum_{k=0}^{\infty}(a_ksinkx+b_kcoskx)\tag{3}\]</span> 要计算出<span class="math inline">\(a_k,b_k\)</span>，用正交函数的积分性质： <span class="math display">\[\int_{-\pi}^{\pi} f(x)sinkxdx=\int_{-\pi}^{\pi}a_ksin^2kxdx=\pia_k\tag{4}\\\int_{-\pi}^{\pi} f(x)coskxdx=\int_{-\pi}^{\pi}a_kcos^2kxdx=\pi b_k\]</span> 注意在三角函数系中只有在周期<span class="math inline">\(2\pi\)</span>上才是正交函数系。为此，希望将周期扩展到任意周期<span class="math inline">\(2L\)</span>，这样，当<span class="math inline">\(L\rightarrow\infty\)</span>，则可将任意函数用三角函数系表出。令 <span class="math display">\[t=\frac{Lx}{\pi}\]</span> 于是式(3)转化为： <span class="math display">\[g(t)=f(x)=f(\frac{\pi t}{L})=\sum_{k=0}^{\infty}(a_ksin\frac{k\pit}{L}+b_kcos\frac{k\pi t}{L})\tag{5}\]</span> 将式(4)中所有<span class="math inline">\(f(*)\)</span>换成<span class="math inline">\(g(*)\)</span> <span class="math display">\[a_k=\frac{1}{L}\int_{-L}^{L} g(t)sin\frac{k\pi t}{L}dt\\b_k=\frac{1}{L}\int_{-L}^{L} g(t)cos\frac{k\pi t}{L}dt\tag{6}\]</span></p><h2 id="频率函数">频率函数</h2><p>​上一节的结论说明任意一个函数可以表示成一系列三角函数之和，为方便表示，令<span class="math inline">\(w_0=\frac{\pi}{L}\)</span>，当<span class="math inline">\(L\rightarrow \infty\)</span>，<span class="math inline">\(w_0\rightarrow 0\)</span>，则<span class="math inline">\(kw_0,(k\in N)\)</span>连续。则 <span class="math display">\[\begin{aligned}g(t)&amp;=\sum_{k=0}^{\infty}(a_ksin\frac{k\pi t}{L}+b_kcos\frac{k\pit}{L})\\&amp;=\sum_{k=0}^{\infty}[(sin\frac{k\pi t}{L})\frac{1}{L}\int_{-L}^{L}g(t)sin\frac{k\pi t}{L}dt+(cos\frac{k\pi t}{L})\frac{1}{L}\int_{-L}^{L}g(t)cos\frac{k\pi t}{L}dt]\\&amp;=\lim_{w_0 \to0}\sum_{k=0}^{\infty}\frac{w_0}{\pi}[sinkw_0t\int_{-\frac{\pi}{w_0}}^{\frac{\pi}{w_0}}g(t)sin(kw_0t)dt+coskw_0t\int_{-\frac{\pi}{w_0}}^{\frac{\pi}{w_0}}g(t)cos(kw_0t)dt]\end{aligned}\tag{7}\]</span>根据积分定义，大区间分成的所有同阶无穷小区间上的任意一点（以下为取小区间左点）函数值的累和为该大区间上的积分：<span class="math display">\[\lim_{\Delta x\to 0,n\to \infty}\sum_{i=0}^{n-1}f(\Delta xi)\Deltax=\int_{0}^{\infty}f(x)dx\tag{8}\]</span> 在式(7)中，注意到<span class="math inline">\(w_0\)</span>为无穷小量，可以将其化为对变量<span class="math inline">\(w\)</span>的积分，因此，(7)(8)有以下对应关系：<span class="math display">\[w_0 \iff \Delta x,f(\Delta xi)\iff\frac{1}{\pi}[sinkw_0t\int_{-\frac{\pi}{w_0}}^{\frac{\pi}{w_0}}g(t)sin(kw_0t)dt+coskw_0t\int_{-\frac{\pi}{w_0}}^{\frac{\pi}{w_0}}g(t)cos(kw_0t)dt]\]</span> 进一步可以得出<span class="math inline">\(f(\Deltaxi)\)</span>的一般形式： <span class="math display">\[f(w)=\frac{1}{\pi}[sinwt\int_{-\infty}^{\infty}g(t)sin(wt)dt+coswt\int_{-\infty}^{\infty} g(t)cos(wt)dt]\]</span> 注意到式(7)中的积分 <span class="math display">\[\int_{-\frac{\pi}{w_0}}^{\frac{\pi}{w_0}} g(t)sin(kw_0t)dt\]</span> 在给定<span class="math inline">\(kw_0\)</span>情况下是一个数值，即在实数范围<span class="math inline">\(R\)</span>上对<span class="math inline">\(t\)</span>的积分，积分上下限即为<span class="math inline">\((-\infty,\infty)\)</span></p><p>于是得到傅里叶变换的一种形式 <span class="math display">\[\begin{aligned}g(t)&amp;=\int_{0}^{\infty} f(w)dw\\f(w)&amp;=\frac{1}{\pi}[sinwt\int_{-\infty}^{\infty}g(t)sin(wt)dt+coswt\int_{-\infty}^{\infty} g(t)cos(wt)dt]\end{aligned}\tag{9}\]</span> 上面的<span class="math inline">\(w\)</span>是三角函数的频率，这组公式揭示了：任意一个函数<span class="math inline">\(g(t)\)</span>等价于无穷多组三角函数（无初相）的和，这些三角函数的频率由第二个公式确定，得到一个频率函数<span class="math inline">\(f(w)\)</span>。根据这些三角函数的频率函数<span class="math inline">\(f(w)\)</span>同样能得到原函数<span class="math inline">\(g(t)\)</span></p><h2 id="一般形式">一般形式</h2><p>在常见的傅里叶变换公式中，一般用如下形式： <span class="math display">\[F(w)=\int_{-\infty}^{\infty} f(t)e^{-iwt}dt\\f(t)=\frac{1}{2\pi}\int_{-\infty}^{\infty}F(w)e^{iwt}dw\tag{10}\]</span>式(10)实际上与式(9)等价。式(10)更简洁，将三角函数用欧拉公式转换成指数形式，且更易计算。下面从(9)推到(10):</p><p>用欧拉公式 <span class="math display">\[e^{i\theta}=cos\theta+isin\theta\]</span> 于是 <span class="math display">\[cos\theta=\frac{e^{i\theta}+e^{-i\theta}}{2}\\sin\theta=-i\frac{e^{i\theta}-e^{-i\theta}}{2}\]</span> 带入(9)中<span class="math inline">\(f(w)\)</span> <span class="math display">\[\begin{aligned}f(w)&amp;=\frac{1}{\pi}[-i\frac{e^{iwt}-e^{-iwt} }{2}\int_{-\infty}^{\infty} g(t)(-i\frac{e^{iwt}-e^{-iwt}}{2})dt+\frac{e^{iwt}+e^{-iwt}}{2}\int_{-\infty}^{\infty}g(t)\frac{e^{iwt}+e^{-iwt} }{2}dt]\\&amp;=\frac{1}{\pi}[-(e^{iwt}-e^{-iwt} ) \int_{-\infty}^{\infty}g(t)(\frac{e^{iwt}-e^{-iwt}}{2})dt+(e^{iwt}+e^{-iwt})\int_{-\infty}^{\infty}g(t)\frac{e^{iwt}+e^{-iwt} }{2}dt]\\&amp;=\frac{1}{\pi}[e^{iwt} \int_{-\infty}^{\infty} g(t)\frac{e^{-iwt}}{2}dt+e^{-iwt} \int_{-\infty}^{\infty} g(t)\frac{e^{iwt} }{2}dt]\\&amp;=\frac{e^{iwt}+e^{-iwt} }{2\pi}\int_{-\infty}^{\infty}g(t)e^{-iwt}dt\end{aligned}\]</span> 令 <span class="math display">\[F(w)=\int_{-\infty}^{\infty} g(t)e^{-iwt}dt\]</span> 注意<span class="math inline">\(F(w)=F(-w)\)</span>，于是<span class="math display">\[\begin{aligned}g(t)&amp;=\int_{0}^{\infty} f(w)dw\\&amp;= \int_{0}^{\infty}\frac{e^{iwt}+e^{-iwt} }{2\pi} F(w)dw\\&amp;=\frac{1}{2\pi}[\int_{0}^{\infty}  F(w)e^{iwt}dw+\int_{0}^{\infty}F(w)e^{-iwt}dw]\\&amp;=\frac{1}{2\pi}[\int_{0}^{\infty}  F(w)e^{iwt}dw+\int_{-\infty}^{0}F(w)e^{iwt}dw]\\&amp;=\frac{1 }{2\pi}\int_{-\infty}^{\infty} F(w)e^{iwt}dw\end{aligned}\]</span> 即得到一般形式傅里叶变换</p>]]></content>
    
    
    <categories>
      
      <category>Math</category>
      
      <category>Calculus</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Math</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>混乱的机器学习</title>
    <link href="/2023/07/08/%E6%B7%B7%E4%B9%B1%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    <url>/2023/07/08/%E6%B7%B7%E4%B9%B1%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</url>
    
    <content type="html"><![CDATA[<hr><span id="more"></span><h1 id="概述">概述</h1><p>以下讨论仅对有标签数据而言。</p><h2 id="no-free-lunch">No Free Lunch</h2><p>NFL告诉我们，一个算法不可能在所有数据上完胜另一个算法。从现在的评估手段来看，这个结论显而易见的，假设算法A在数据集D=（特征列X，类别列Y）上的准确率超过了算法B，那么我们只要在D的类别列Y上动手脚，把原来D的类别以某种顺序重新排列得到新的数据集D‘，最终能得到B的准确率超过A（A更倾向于把符合某些特征的样本分类成正确的，而我们把这部分A的优势样本的类故意改成错的）。可以说，NFL定理是机器学习的梦魇。实验证明，在UCIHeart数据集上，多少层深度网络都不是经典决策树的对手。在Six-HumpCamel-BackFunction上，一众新型动物园算法输给了经典遗传算法。（这两个问题都会在后面详细阐述原因）然而，正因NFL的存在，贡献了ML领域99%的论文😓</p><h2 id="方向">方向？</h2><p>既然NFL存在，那么我们就不能奢求一个更好的算法了吗？其实，NFL的前提是依据一些评估指标去评估分类效果，在这个前提下，不存在最优算法。然而，如果算法A的准确率低于算法B，是否能够说明在这个数据集上，A的效果一定劣于B？周志华《机器学习》假设目标函数是服从均匀分布的随机变量，因此给出NFL的证明。然而，是否因为存在这样的数据集，就无法比较算法的优劣？我认为不是。机器学习本质上是从数据中找规律，数据特征列与目标列并不是独立的，这样的数据才是有分析意义的。在这个角度考虑，算法就存在优劣。例如，实验经验告诉我们，对于时序相关数据，LSTM等循环网络通常优于全连接网络。但是，关于算法优劣比较目前的定义仍旧十分模糊。下面讨论各个主流方向存在的问题，并给出我的一些偏见。为避免误会，在此规定用词：“特征”是数据集的列，“数据集”是"样本"组成的，每个样本可以当作一个多元函数，该函数的每个变量就是特征。“条件”是描述算法理论的词，在计算条件熵时，每个特征作为一个条件。</p><h1 id="内分析">内分析</h1><p>一些算法试图分析数据的一些特点，另一些则首先建立起一个模型，通过一些手段让这个模型尽可能贴合数据。</p><h2 id="信息与噪音">信息与噪音</h2><p>​现在公认的公理：数据=信息+噪音。有效的信息就是信息，无效的信息就是噪音。然而，信息和噪音的界限在哪里？如何剔除数据中的噪音，然后只对信息进行？这个问题是至关重要的，可以说，解决了这个问题，所有问题就可以解决了，我们可以让分类回归算法达到完美的效果。遗憾的是，这个问题至今没有一种合理的解决办法。仅有一些降低噪音的方法（后面会提到，这些方法是否真的有效）。</p><h3 id="信息熵">信息熵</h3><p>有一些算法希望解决这个问题，例如信息熵 <span class="math display">\[H(X)=-\sum_{i=1}^{n}p_ilogp_i,\quad \sum_{i=1}^{n}p_i=1\]</span>这个定义有个好处，把信息和概率联系起来了。把每一种情况的信息量的数学期望作为信息熵来考虑，完美符合了信息的可加性，也就是<span class="math display">\[I(A)+I(B)=-logp_A+(-logp_B)=-logp_Ap_B\]</span> 其中<span class="math inline">\(A,B\)</span>是两个独立随机事件，<span class="math inline">\(I(A),I(B)\)</span>是<span class="math inline">\(A,B\)</span>的信息量。同样地可以计算在某个条件下所有随机事件的信息熵的数学期望，简称条件熵。用原始信息熵-条件熵，也就得到了这个特征带来的信息增益：<span class="math display">\[特征C带来的信息增益=H(原始数据集分类取值Y)-\sum_{特征C的每种情况c_i}H(c_i下的数据的分类取值Y_i)p_i\]</span>在ID3算法中采用了信息增益来衡量特征的重要性，这是一个很好的想法，显然这又是另一条公理：独立事件带来的信息量是可加的。然而传统信息熵存在严重缺陷，它是离散的，并且这个信息熵函数本身是随n增大而趋于0.因此，类别数不同的信息熵的量纲也不同。为此，ID3的升级版C4.5算法则采用了信息增益比，用某特征的信息增益÷该特征的信息熵=该特征的信息增益比，用来缓解不同特征类别不同导致的不同特征信息熵量纲不同。然而信息增益比的计算方式也并非严谨统一了不同类别信息熵的量纲，只是一定程度上降低了其影响。</p><h3 id="相对熵">相对熵</h3><h1 id="外分析">外分析</h1><h2 id="按图索骥">按图索骥</h2><p>神经网络通过最小化损失函数来使预先建立的模型拟合数据，但是，每个结构不同的神经网络都拟合出了一个与众不同的函数，而符合数据集的实际上只有一个。哪怕损失可以降到0，最终仍然几乎不可能得到数据集中蕴含的函数关系。这是因为，有限的点可以符合无穷多个分布，损失小的神经网络拟合出的函数也只是无穷多个分布里的沧海一粟，那么这时奥卡姆剃刀就派上用场了。然而损失小的神经网络里面难道最简单的那个就最符合数据？显然不是，只是方便计算。另外，一般的数据都不会有过于复杂的关系，比如<span class="math inline">\(y=e^{\sum{sin(x_i)}}\)</span>，用神经网络大概能得到一个多项式级别的关系。这也够应付大多数数据了，</p>]]></content>
    
    
    <categories>
      
      <category>ML</category>
      
      <category>Summary</category>
      
    </categories>
    
    
    <tags>
      
      <tag>ML</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MIMIC-IV-DERIVED 模块详解</title>
    <link href="/2023/05/05/MIMIC-IV-DERIVED/"/>
    <url>/2023/05/05/MIMIC-IV-DERIVED/</url>
    
    <content type="html"><![CDATA[<h1 id="简介">简介</h1><p>MIMIC-IV DERIVED模块在官方文档并未给出解释，仅提供生成表的SQL。(详见https://github.com/MIT-LCP/mimic-iv）我将结合生成该模块所有表的SQL逐一解释每一个表内容与意义。</p><p>注意，在该数据库中出现的所有时间都被加上了某个随机偏移量。同一个患者的所有时间信息的偏移量是相同的。由此可以计算时间差来获得一些特征，如入院存活时间。</p><h1 id="编号">编号</h1><p>在该模块中所有表都包含了subject_id, hadm_id</p><h2 id="subject_id">subject_id</h2><p>患者编号，每个患者只有一个subject_id</p><h2 id="hadm_id">hadm_id</h2><p>就诊编号。一个患者可以有多次就诊记录，一个subject_id可对应多个hadm_id</p><h1 id="demographics">demographics</h1><h2 id="age">age</h2><h3 id="admittime">admittime</h3><p>入院时间。</p><h3 id="anchor_age">anchor_age</h3><p>真实年龄。整型</p><h3 id="anchor_year">anchor_year</h3><p>基准年份，用于计算真实年龄的准确值。整型。</p><h3 id="age-1">age</h3><p>年龄的准确值。浮点型</p><h2 id="icustay_detail">icustay_detail</h2><h3 id="stay_id">stay_id</h3><p>患者进入ICU的编号。一个subject_id可以有多个stay_id。整型</p><h3 id="gender">gender</h3><p>性别。有M，F两种取值</p><h3 id="dod">dod</h3><p>入院直至离院1年期间的死亡时间。date类型。若为NULL则表示没有在这个时间范围内死亡</p><h3 id="admittime-1">admittime</h3><p>入院时间。date类型</p><h3 id="dischtime">dischtime</h3><p>离院时间。date类型</p><h3 id="los_hospital">los_hospital</h3><p>住院时间。los_hospital=dischtime-admittime. date类型，单位是天</p><h3 id="admission_age">admission_age</h3><p>年龄精确值，float类型</p><h3 id="race">race</h3><p>种族。文本型</p><h3 id="hospital_expire_flag">hospital_expire_flag</h3><p>住院期间死亡标志。为1代表在住院期间死亡。为0代表未在住院期间死亡</p><h3 id="hospital_seq">hospital_seq</h3><p>数字，代表同一个患者第几次入院。</p><h3 id="first_hosp_stay">first_hosp_stay</h3><p>是否为第一次入院。为t代表true，f代表false</p><h3 id="icu_intime">icu_intime</h3><p>进入icu的时间，date类型</p><h3 id="icu_outtime">icu_outtime</h3><p>出icu时间，date类型</p><h3 id="los_icu">los_icu</h3><p>在icu的停留时间，float类型，单位是天</p><h3 id="icustay_seq">icustay_seq</h3><p>数字，代表同一个患者第几次入icu。</p><h3 id="first_icu_stay">first_icu_stay</h3><p>是否为第一次入icu。为t代表true，f代表false</p><h2 id="icustay_hourly">icustay_hourly</h2><h3 id="stay_id-1">stay_id</h3><p>患者进入ICU的编号。一个subject_id可以有多个stay_id。整型</p><h3 id="hr">hr</h3><p>每个stay_id对应从-24到icu停留的最大时间，整型。hr等于0时代表入icu时间。</p><h3 id="end_time">end_time</h3><p>date类型</p><p>##icustay_times</p><h3 id="stay_id-2">stay_id</h3><p>患者进入ICU的编号。一个subject_id可以有多个stay_id。整型</p><h3 id="intime_hr">intime_hr</h3><p>入icu时间，date类型</p><h3 id="outtime_hr">outtime_hr</h3><p>出icu时间，date类型</p><h2 id="weight_durations">weight_durations</h2><h3 id="starttime">starttime</h3><p>每个患者的第一个stay_id对应的starttime是入icu时间，对应weight_type为admit，之后的stay_id对应的starttime是下一次测量体重时间，对应的weight_type为daily</p><h3 id="endtime">endtime</h3><p>每个患者的最后一个stay_id对应的endtime是出icu时间，之前的endtime对应stay_id下一次测试体重的时间</p><h3 id="weight">weight</h3><p>体重，float类型</p><h3 id="weight_type">weight_type</h3><p>有两个取值admit和daily，为admit则为首次测量，为daily为之后测量</p><h1 id="comorbidity">comorbidity</h1><h2 id="charlson">charlson</h2><p>提取了Charlson Comorbidity Index(CCI)，Charlson ComorbidityIndex（CCI）是用于评估患者基础疾病负担和死亡风险的一种评分系统。该指数基于患者的医学记录，包括过去的病史和诊断记录，并为每个患者分配一个CCI分数。该分数根据患者是否有特定的基础疾病（如心血管疾病、糖尿病等）以及这些疾病的严重程度进行计算。CCI被广泛应用于临床研究中，以评估患者的整体健康状况和治疗效果。评分越高，疾病情况越严重</p><p>该表的列代表了Charlson ComorbidityIndex评分系统中的各个部分，具体如下：</p><ul><li>'age_score': 年龄得分</li><li>'myocardial_infarct': 心肌梗塞</li><li>'congestive_heart_failure': 充血性心力衰竭</li><li>'peripheral_vascular_disease': 周围血管疾病</li><li>'cerebrovascular_disease': 脑血管疾病</li><li>'dementia': 痴呆症</li><li>'chronic_pulmonary_disease': 慢性肺部疾病</li><li>'rheumatic_disease': 风湿疾病</li><li>'peptic_ulcer_disease': 消化性溃疡</li><li>'mild_liver_disease': 轻度肝病</li><li>'diabetes_without_cc': 没有并发症的糖尿病</li><li>'diabetes_with_cc': 有并发症的糖尿病</li><li>'paraplegia':截瘫</li><li>'renal_disease': 肾脏疾病</li><li>'malignant_cancer': 恶性肿瘤</li><li>'severe_liver_disease': 重度肝病</li><li>'metastatic_solid_tumor': 实体瘤转移</li><li>'aids': 艾滋病</li><li>'charlson_comorbidity_index': Charlson Comorbidity Index总评分</li></ul><h2 id="first_day_lab">first_day_lab</h2><p>第一天实验室化验指标，都为float类型，如下：</p><p>hematocrit_min/max: 最低/最高红细胞比容 hemoglobin_min/max:最低/最高血红蛋白 platelets_min/max: 最低/最高血小板计数 wbc_min/max:最低/最高白细胞计数 albumin_min/max: 最低/最高白蛋白 globulin_min/max:最低/最高球蛋白 total_protein_min/max: 最低/最高总蛋白 aniongap_min/max:最低/最高阴离子间隙 bicarbonate_min/max: 最低/最高碳酸氢根离子bun_min/max: 最低/最高尿素氮 calcium_min/max: 最低/最高钙chloride_min/max: 最低/最高氯 creatinine_min/max: 最低/最高肌酐glucose_min/max: 最低/最高血糖 sodium_min/max: 最低/最高钠potassium_min/max: 最低/最高钾 abs_basophils_min/max:最低/最高嗜碱性粒细胞计数 abs_eosinophils_min/max:最低/最高嗜酸性粒细胞计数 abs_lymphocytes_min/max: 最低/最高淋巴细胞计数abs_monocytes_min/max: 最低/最高单核细胞计数 abs_neutrophils_min/max:最低/最高中性粒细胞计数 atyps_min/max: 最低/最高异形淋巴细胞计数bands_min/max: 最低/最高带状核粒细胞计数 imm_granulocytes_min/max:最低/最高未成熟粒细胞计数 metas_min/max: 最低/最高幼稚红细胞计数nrbc_min/max: 最低/最高早幼红细胞计数 d_dimer_min/max: 最低/最高D-二聚体fibrinogen_min/max: 最低/最高纤维蛋白原 thrombin_min/max:最低/最高凝血酶时间 inr_min/max: 最低/最高国际标准化比值 pt_min/max:最低/最高凝血酶原时间 ptt_min/max: 最低/最高部分凝血活酶时间alt_min/max: 最低/最高丙氨酸氨基转移酶 alp_min/max: 最低/最高碱性磷酸酶ast_min/max: 最低/最高天门冬氨酸氨基转移酶 amylase_min/max:最低/最高淀粉酶 bilirubin_total_min/max: 最低/最高总胆红素bilirubin_direct_min/max: 最低/最高直接胆红素bilirubin_indirect_min/max: 最低/最高间接胆红素 ck_cpk_min/max:最低/最高肌酸激酶 ck_mb_min/max: 最低/最高肌酸激酶同工酶 ggt_min/max:最低/最高谷氨酰转肽酶ld_ldh_min/max: 最低/最高乳酸脱氢酶</p><h1 id="firstday">firstday</h1><h2 id="first_day_bg">first_day_bg</h2><p>最高/最低血气测量值，包括所有标本（静脉/动脉/混合）</p><p>##first_day_bg_art</p><p>动脉血标本的最高/最低血气值</p><h2 id="first_day_gcs">first_day_gcs</h2><p>GCS:格拉斯哥昏迷评分，一种衡量神经功能的方法。范围为3（最差，昏迷）到15（最佳，正常功能）。该表包括：</p><ul><li>'gcs_min'：表示最低的GCS得分，即3分。</li><li>'gcs_motor'：表示GCS评分中与肢体运动反应相关的参数。包括6个等级</li><li>'gcs_verbal'：表示GCS评分中与言语反应相关的参数。包括5个等级</li><li>'gcs_eyes'：表示GCS评分中与眼睛反应相关的参数。包括4个等级</li><li>'gcs_unable'：表示无法对患者进行GCS评分的情况，通常是由于患者昏迷或严重头部损伤等原因导致。</li></ul><h2 id="first_day_height">first_day_height</h2><h3 id="height">height</h3><p>身高</p><h2 id="first_day_rrt">first_day_rrt</h2><p>RRT是肾脏替代治疗（Renal ReplacementTherapy）的缩写，是一种透析治疗方式。肾脏替代治疗是一组用于替代肾脏功能的技术，包括血液透析、腹膜透析和连续性肾脏替代治疗等。这些技术可以帮助患者清除血液中的废物和多余的水分，并纠正电解质紊乱和酸碱平衡问题，从而改善肾功能受损患者的生命质量。在重症患者中，RRT通常被用于治疗急性肾损伤，以及其他导致肾脏功能衰竭的情况。</p><h2 id="first_day_sofa">first_day_sofa</h2><p>Sequential Organ FailureAssessment（SOFA）评分系统是一种衡量患者多重器官功能障碍的严重程度和进展情况的标准。SOFA评分包括以下6个部分：</p><ol type="1"><li>呼吸系统(respiration)：用PaO2/FiO2比值来评估呼吸功能。</li><li>血液系统(coagulation)：用血小板计数来评估凝血功能。</li><li>肝脏系统(liver)：用胆红素水平来评估肝功能。</li><li>心血管系统(cardiovascular)：用平均动脉压或血流动力学指标来评估心功能。</li><li>中枢神经系统(cns)：用格拉斯哥昏迷评分（GCS）来评估神经系统功能。</li><li>肾脏系统(renal)：用肌酐水平来评估肾功能。</li></ol><p>每个部分都有特定的评分标准，每一项评分从0到6，总分从0到24。SOFA评分越高，表示患者器官功能障碍越严重。SOFA评分系统通常用于评估急性生命威胁疾病的严重程度，例如感染、创伤、中毒等。</p><h2 id="first_day_urine_output">first_day_urine_output</h2><p>Urineoutput是指尿液排出的量，通常以毫升（mL）为单位计量。人体通过肾脏过滤血液中的废物和多余的水分，形成尿液并将其排出体外。正常情况下，24小时内的尿液产生量在800到2000毫升之间，但这个数字也会因人而异，取决于饮食、身体活动水平和药物使用等因素。测量尿量可以反映肾脏的功能状态，对诊断肾脏疾病、评估液体平衡和监测治疗效果等方面都有重要意义。在医院和临床环境中，经常会通过监测尿量来判断患者是否需要输液或调整药物剂量。</p><p>Urine output过大可能是：</p><ul><li>糖尿病等代谢性疾病</li><li>尿路感染</li><li>肾脏疾病</li></ul><p>过小可能是：</p><ul><li>脱水</li><li>肾衰竭</li><li>尿路梗阻</li><li>某些药物的不良反应等</li></ul><h2 id="first_day_vitalsign">first_day_vitalsign</h2><p>Vitalsign（生命体征）是指用来测量身体各种基本生理功能的一组指标。</p><p>heart_rate_min：心率最小值</p><p>heart_rate_max：心率最大值</p><p>heart_rate_mean：平均心率</p><p>sbp_min：收缩压最小值</p><p>sbp_max：收缩压最大值</p><p>sbp_mean：平均收缩压</p><p>dbp_min：舒张压最小值</p><p>dbp_max：舒张压最大值</p><p>dbp_mean：平均舒张压</p><p>mbp_min：平均动脉压最小值</p><p>mbp_max：平均动脉压最大值</p><p>mbp_mean：平均动脉压</p><p>resp_rate_min：呼吸频率最小值</p><p>resp_rate_max：呼吸频率最大值</p><p>resp_rate_mean：平均呼吸频率</p><p>temperature_min：体温最小值</p><p>temperature_max：体温最大值</p><p>temperature_mean：平均体温</p><p>spo2_min：血氧饱和度最小值</p><p>spo2_max：血氧饱和度最大值</p><p>spo2_mean：平均血氧饱和度</p><p>glucose_min：血糖最小值</p><p>glucose_max：血糖最大值</p><p>glucose_mean：平均血糖</p><h2 id="first_day_weight">first_day_weight</h2><h1 id="药物">药物</h1><h2 id="antibiotic">antibiotic</h2><p>该表对应的SQL如下，可以看出该表来自mimiciv_icu.icustays与mimiciv_hosp.prescriptions的部分列。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <br>pr.subject_id, pr.hadm_id<br>, ie.stay_id<br>, pr.drug <span class="hljs-keyword">as</span> antibiotic<br>, pr.route<br>, pr.starttime<br>, pr.stoptime<br><span class="hljs-keyword">from</span> mimiciv_hosp.prescriptions pr<br><span class="hljs-comment">-- inner join to subselect to only antibiotic prescriptions</span><br><span class="hljs-keyword">inner</span> <span class="hljs-keyword">join</span> abx<br>    <span class="hljs-keyword">on</span> pr.drug <span class="hljs-operator">=</span> abx.drug<br>    <span class="hljs-comment">-- route is never NULL for antibiotics</span><br>    <span class="hljs-comment">-- only ~4000 null rows in prescriptions total.</span><br>    <span class="hljs-keyword">AND</span> pr.route <span class="hljs-operator">=</span> abx.route<br><span class="hljs-comment">-- add in stay_id as we use this table for sepsis-3</span><br><span class="hljs-keyword">LEFT</span> <span class="hljs-keyword">JOIN</span> mimiciv_icu.icustays ie<br>    <span class="hljs-keyword">ON</span> pr.hadm_id <span class="hljs-operator">=</span> ie.hadm_id<br>    <span class="hljs-keyword">AND</span> pr.starttime <span class="hljs-operator">&gt;=</span> ie.intime<br>    <span class="hljs-keyword">AND</span> pr.starttime <span class="hljs-operator">&lt;</span> ie.outtime<br><span class="hljs-keyword">WHERE</span> abx.antibiotic <span class="hljs-operator">=</span> <span class="hljs-number">1</span><br>;<br></code></pre></td></tr></table></figure><h3 id="stay_id-3">stay_id</h3><p>患者进入ICU的编号。一个subject_id可以有多个stay_id。整型</p><h3 id="antibiotic-1">antibiotic</h3><p>患者使用抗生素。文本型。</p><h3 id="route">route</h3><p>使用抗生素的方式，总共有35种。</p><h3 id="starttimestoptime">starttime,stoptime</h3><p>使用抗生素的起止时间</p><h1 id="化验">化验</h1><p>该部分的表都包括charttime，表示样本检测时间。</p><h2 id="bg">bg</h2><p>该表包含了blood gases的化验结果。</p><h3 id="specimen">specimen</h3><p>样本的采集位置。有四种类型：</p><ul><li>CENTRALVENOUS：中心静脉。位于体内靠近心脏的静脉，通常用于输液、血管插管和监测中心静脉压等医疗程序。</li><li>MIX：混合的血液样本。当人体的动脉血和静脉血混合时，得到的血液样本就称为混合的血液样本。在某些情况下，如心脏病或肺部疾病，测量混合血气可以更好地反映身体的氧合状态。</li><li>VEN.：静脉血。指采集自人体静脉的血液样本，在血气分析中通常用于了解身体排出的二氧化碳和酸碱平衡情况。</li><li>ART.：动脉血。指采集自人体动脉的血液样本，在血气分析中通常用于了解身体组织的氧合状态。</li></ul><p>注意，不同采集位置的血液样本测量值可能会有一定的差异。</p><h3 id="其他指标">其他指标</h3><p>该表的其他列表示血气测量结果，具体说明如下：</p><ul><li>glucose（葡萄糖）: 正常值为70-99 mg/dL。</li><li>so2（氧饱和度）:血液中被氧气所结合的血红蛋白的百分比，通常在95%-100%之间。</li><li>po2（动脉血氧分压）: 正常值为75-100 mmHg。</li><li>pco2（动脉血二氧化碳分压）: 正常值为35-45 mmHg。</li><li>fio2_chartevents（吸氧浓度）:通常表示机械通气时给予的氧气浓度，正常值为21%至100%。</li><li>fio2（吸氧浓度）: 同上，正常值为21%至100%。</li><li>aado2（动脉-静脉氧分压差）: 血气分析结果中PaO2和PvO2之差，通常在5-15mmHg之间。</li><li>aado2_calc（计算得到的动脉-静脉氧分压差）:采用公式计算得到的动脉-静脉氧分压差，通常在5-15 mmHg之间。</li><li>pao2fio2ratio（动脉血氧分压/吸入氧气浓度比值）:通常在300-500之间。</li><li>ph（血液酸碱度）: 正常值为7.35-7.45。</li><li>baseexcess（碱剩余量）: 血液中碱性物质的含量，正常值为-2到+2mmol/L。</li><li>bicarbonate（碳酸氢盐）: 正常值为22-28 mmol/L。</li><li>totalco2（二氧化碳总量）: 正常值为22-30 mmol/L。</li><li>hematocrit（红细胞压积）:血液中红细胞所占比例，正常值为男性40%-54%，女性37%-47%。</li><li>hemoglobin（血红蛋白）: 正常值为男性13.5-17.5 g/dL，女性12.0-15.5g/dL。</li><li>carboxyhemoglobin（羧血红蛋白）:血液中一种与一氧化碳结合的血红蛋白，正常值为不超过2.5%。</li><li>methemoglobin（高铁血红蛋白）:血液中一种氧化铁血红蛋白，正常值为不超过1%。</li><li>chloride（氯离子）: 正常值为96-106 mEq/L。</li><li>calcium（钙离子）: 正常值为8.5-10.5 mg/dL。</li><li>temperature（体温）: 正常值为36.5-37.5℃。</li><li>potassium（钾离子）: 正常值为3.5-5.0 mEq/L。</li><li>sodium（钠离子）: 正常值为135-145 mEq/L。</li><li>lactate（乳酸）: 正常值为0.5-2.2 mmol/L。</li></ul><h2 id="blood_differential">blood_differential</h2><p>该表包含了白细胞计数的测量值</p><h3 id="specimen_id">specimen_id</h3><p>化验样品编号。在这里，每个hadm_id和specimen_id一一对应，将原表hosp.labevents的每个患者每次的不同的化验项合并为一条。</p><h3 id="其他指标-1">其他指标</h3><p>该表的其他列给出了白细胞计数的测量结果，说明如下：</p><ul><li>WBC：白细胞总数。正常值范围通常在4,500/μL到11,000/μL之间。</li><li>Basophils_abs：嗜碱性粒细胞绝对计数。正常值范围通常在0到200/μL之间。</li><li>Eosinophils_abs：嗜酸性粒细胞绝对计数。正常值范围通常在15到500/μL之间。</li><li>Lymphocytes_abs：淋巴细胞绝对计数。正常值范围通常在1,000到4,800/μL之间。</li><li>Monocytes_abs：单核细胞绝对计数。正常值范围通常在200到950/μL之间。</li><li>Neutrophils_abs：中性粒细胞绝对计数。正常值范围通常在2,500到7,000/μL之间。</li><li>Basophils：嗜碱性粒细胞相对计数。正常值范围通常在0到2%之间。</li><li>Eosinophils：嗜酸性粒细胞相对计数。正常值范围通常在1到6%之间。</li><li>Lymphocytes：淋巴细胞相对计数。正常值范围通常在25到40%之间。</li><li>Monocytes：单核细胞相对计数。正常值范围通常在2到10%之间。</li><li>Neutrophils：中性粒细胞相对计数。正常值范围通常在50到70%之间。</li><li>Atypical_lymphocytes:非典型淋巴细胞计数。正常值范围通常在0到2%之间。</li><li>Bands: 未成熟粒细胞计数。正常值范围通常在0到6%之间。</li><li>Immature_granulocytes:未成熟粒细胞绝对计数。正常值范围通常在0到300/μL之间。</li><li>Metamyelocytes:早幼粒细胞绝对计数。正常值范围通常在0到200/μL之间。</li><li>NRBC:有核红细胞计数。正常成人血液中不应该存在NRBC。如果检测出现NRBC，则可能提示某些健康问题，例如贫血、骨髓增生异常综合征等。</li></ul><h2 id="chemistry">chemistry</h2><p>该表包含了化学元素的化验结果。</p><h3 id="其他指标-2">其他指标</h3><p>该表的其他列给出了每种化验项的测量结果，各个化验项说明如下：</p><ul><li>白蛋白（Albumin）：在肝脏中合成的一种蛋白质，可以反映身体内的营养状况和肝功能。</li><li>球蛋白（Globulin）：一种蛋白质类别，包括多个不同种类的蛋白质，可以反映免疫系统的活动情况和某些疾病的存在。</li><li>总蛋白（TotalProtein）：血液中所有蛋白质的总量，是一个综合指标，可以反映身体内的营养状况和肝功能。</li><li>阴离子间隙（Anion Gap）：用于评估血液酸碱平衡状态的指标。</li><li>碳酸氢根离子（Bicarbonate）：参与调节血液酸碱平衡的一种离子。</li><li>尿素氮（Blood Urea Nitrogen，BUN）：用于评估肾功能的指标。</li><li>钙（Calcium）：参与调节神经、肌肉和骨骼等方面的重要离子。</li><li>氯（Chloride）：参与调节血液酸碱平衡和水分平衡的离子。</li><li>肌酐（Creatinine）：用于评估肾功能的指标。</li><li>葡萄糖（Glucose）：血液中的主要能量来源，用于评估糖尿病和其他代谢问题。</li><li>钠（Sodium）：参与调节神经、肌肉和水分平衡等方面的重要离子。</li><li>钾（Potassium）：参与调节心脏、肌肉和水分平衡等方面的重要离子。</li></ul><p>以下是每个指标的正常取值范围：</p><ul><li>白蛋白（Albumin）：3.5-5.0 g/dL</li><li>球蛋白（Globulin）：2.0-3.5 g/dL</li><li>总蛋白（Total Protein）：6.0-8.3 g/dL</li><li>阴离子间隙（Anion Gap）：8-16 mmol/L</li><li>碳酸氢根离子（Bicarbonate）：22-28 mmol/L</li><li>尿素氮（Blood Urea Nitrogen，BUN）：7-20 mg/dL</li><li>钙（Calcium）：8.5-10.5 mg/dL</li><li>氯（Chloride）：96-106 mmol/L</li><li>肌酐（Creatinine）：0.6-1.2 mg/dL</li><li>葡萄糖（Glucose）：70-100 mg/dL</li><li>钠（Sodium）：135-145 mmol/L</li><li>钾（Potassium）：3.5-5.0 mmol/L</li></ul><p>需要注意的是，这些正常取值范围可能会因年龄、性别、肝肾功能等因素而有所不同。</p><h2 id="感染">感染</h2><h3 id="sepsis">sepsis</h3><p>Sepsis是一种严重的感染性疾病，通常是由细菌、病毒或真菌引起的。当身体对感染做出反应时，可能会释放出过多的化学物质，导致全身炎症反应，进而损害器官和组织。这种炎症反应称为“全身性炎症反应综合征”（SystemicInflammatory ResponseSyndrome，SIRS）。当SIRS与感染同时存在时，就被称为Sepsis。Sepsis可以因感染部位不同而表现出各种症状，包括高热、寒战、心率加快、呼吸急促、低血压、虚弱乏力等。在严重情况下，Sepsis可能导致休克、器官功能衰竭和死亡。</p><h3 id="suspicion_of_infection">suspicion_of_infection</h3><h3 id="positive_culture">positive_culture</h3><p>微生物学检查。如果该值为1表示采集样本微生物培养的结果为阳性，存在微生物感染。</p>]]></content>
    
    
    
    <tags>
      
      <tag>database</tag>
      
      <tag>ML</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>矩阵论</title>
    <link href="/2023/04/27/%E7%9F%A9%E9%98%B5%E8%AE%BA/"/>
    <url>/2023/04/27/%E7%9F%A9%E9%98%B5%E8%AE%BA/</url>
    
    <content type="html"><![CDATA[<span id="more"></span><h1 id="矩阵导数">矩阵导数</h1><p>​矩阵导数即对矩阵的多个元素求导，作为一种简便的计算方式。在下面的计算过程中，标量，向量均作为特殊的矩阵，如无指出是标量或向量，矩阵的含义均包括了是标量，向量，矩阵的情况。在矩阵导数中，因变量矩阵的每个元素与自变量矩阵中的每个元素均存在映射。</p><p>​在可能混淆的地方，小写字母为标量，加粗或希腊字母为向量，大写字母为矩阵。在函数中用<span class="math inline">\(y,Y\)</span>做自变量，<span class="math inline">\(f\)</span>表示函数关系，<span class="math inline">\(dy,dY\)</span>表示全微分，<span class="math inline">\(\frac{\partial f}{\partial x_i}\)</span>表示<span class="math inline">\(y\)</span>对<span class="math inline">\(x_i\)</span>的偏导数。将矩阵每个元素视为自变量，要求因变量（标量或矩阵）对该矩阵每个元素的导数构成的矩阵。在不引起混淆的情况下，使用<span class="math inline">\(f&#39;(X)\)</span>作为<span class="math inline">\(\frac{\partial f(X)}{\partialX}\)</span>的简写形式。</p><p>​ 在形如<span class="math inline">\(Y=f(X_{m\timesn})\)</span>的矩阵运算中，自变量矩阵<span class="math inline">\(X\)</span>每个元素与因变量矩阵<span class="math inline">\(Y\)</span>存在映射，因此<span class="math inline">\(Y\)</span>为1×1矩阵(或标量)时，<span class="math inline">\(\frac{\partial f}{\partial X}\)</span>应有<span class="math inline">\(m\times n\)</span>个元素，若<span class="math inline">\(Y\)</span>为<span class="math inline">\(p\timesq\)</span>矩阵时，<span class="math inline">\(\frac{\partial f}{\partialX}\)</span>应有<span class="math inline">\(p\times q\times m\timesn\)</span>个元素。然而，这可能有多种表示方式。本文采用向量化方法，详见下。</p><h2 id="计算技巧">计算技巧</h2><h3 id="hadamard积">Hadamard积</h3><p>对同形矩阵<span class="math inline">\(A,B\in R^{m\timesn}\)</span>，表现为按元素乘: <span class="math display">\[[A\odot B]_{ij}=a_{ij}b_{ij}\]</span> 在numpy中可以直接将两个同形矩阵相乘：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br>A = np.array([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>], [<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]])<br>B = np.array([[<span class="hljs-number">5</span>, <span class="hljs-number">6</span>], [<span class="hljs-number">7</span>, <span class="hljs-number">8</span>]])<br>Hadamard_A_B = A*B<br></code></pre></td></tr></table></figure><h3 id="kronecker积">Kronecker积</h3><p>对于<span class="math inline">\(A\in R^{m\times n},B\in R^{p\timesq}\)</span>，B对A中每个元素<span class="math inline">\(a_{ij}\)</span>进行数乘并将结果取代<span class="math inline">\(a_{ij}\)</span>位置: <span class="math display">\[[A\otimes B]_{ij}=a_{ij}B\]</span> numpy实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br>A = np.array([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>], [<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]])<br>B = np.array([[<span class="hljs-number">5</span>, <span class="hljs-number">6</span>], [<span class="hljs-number">7</span>, <span class="hljs-number">8</span>]])<br>Kronecker_A_B = np.kron(A, B)<br></code></pre></td></tr></table></figure><h3 id="向量化">向量化</h3><p><span class="math inline">\(vec(X_{m\times n})\)</span>表示将<span class="math inline">\(X\)</span>逐列转换为列向量： <span class="math display">\[[vec(X)]_{i}=X_{[\frac{i}{m}],i-m[\frac{i}{m}]+1}\]</span> 其中<span class="math inline">\([a]\)</span>表示对有理数<span class="math inline">\(a\)</span>向下取整。在numpy中使用reshape()即可。</p><h3 id="变量矩阵等价的唯一性">变量矩阵等价的唯一性</h3><p>​ 对于变量矩阵<span class="math inline">\(X_{mn},Y_{nq},Z_{nq}\)</span>，若存在<span class="math inline">\(X=X&#39;\)</span>使得<span class="math inline">\(X\)</span>列满秩，且有<span class="math inline">\(XY=XZ\)</span>，则<span class="math inline">\(Y=Z\)</span>。关于这个结论，暂未查找到资料。然而这是十分重要的。所以，在此给出一个证明。</p><p>​ For all column vectors <span class="math inline">\(X_{.1},X_{.2},...X_{.n}\)</span> in <span class="math inline">\(X\)</span>： <span class="math display">\[k_1X_{.1}+k_2X_{.2}+...+k_nX_{.n}=0 \quad \Rightarrowk_1,k_2,...k_n=0\tag{1}\]</span> ​ Suppose <span class="math inline">\(Y\neq Z,XY=XZ\)</span>,then <span class="math display">\[X(Y-Z)=0\]</span> ​ Let <span class="math inline">\(W=Y-Z\)</span>, <span class="math inline">\(W\neq 0\)</span>, for all column vectors <span class="math inline">\(W_{.1},W_{.2}...W_{.q}\)</span> in W: <span class="math display">\[\exists {i} \quad s.t.W_{.i}\neq0\]</span> Consider the multiplication of <span class="math inline">\(X\)</span> and <span class="math inline">\(W_{.i}\)</span>: <span class="math display">\[XW_{.i}=(X_{.1},X_{.2},...X_{.n})W_{.i}=X_{.1}W_{1i}+X_{.2}W_{2i}+...X_{.n}W_{ni}=0\]</span> ​与(1)矛盾。对于可行满秩的变量矩阵，同理，改为左乘即可。在下面计算矩阵导数时将用到这个结论。</p><h2 id="多元函数导数">多元函数导数</h2><p>​ 对于多元函数<span class="math display">\[y=f(x_1,x_2,...,x_n)\]</span>，其微分<span class="math inline">\(dy\)</span>为： <span class="math display">\[dy=\sum_{i=1}^{n}\frac{\partial f}{\partial x_i}dx_i\]</span> 以向量形式表示，令 <span class="math display">\[d\mathbf{x}=(dx_1,dx_2,...,dx_n)\\\frac{\partial f}{\partial \mathbf{x}}=(\frac{\partial f}{\partialx_1},\frac{\partial f}{\partial x_2},...,\frac{\partial f}{\partialx_n})\]</span> <span class="math inline">\(\frac{\partial f}{\partial\mathbf{x} }\)</span>即在点<span class="math inline">\((x_1,x_2,...,x_n)\)</span>的梯度。则将<span class="math inline">\(dy\)</span>表示为 <span class="math display">\[dy=\frac{\partial f}{\partial \mathbf{x}}^Td\mathbf{x}\]</span></p><h2 id="标量对矩阵导数">标量对矩阵导数</h2><p>​ 对于<span class="math inline">\(y=f(X_{m\times n})\)</span>，<span class="math inline">\(f\)</span>将矩阵<span class="math inline">\(X\)</span>映射为标量，<span class="math inline">\(y\)</span>与<span class="math inline">\(X\)</span>的全体元素存在映射关系。仿照多元函数，微分<span class="math inline">\(dy\)</span>为： <span class="math display">\[dy=\sum_{i=1}^{m}{\sum_{j=1}^{n}{\frac{\partial f}{\partial X_{ij} } }}dX_{ij}\]</span> 其中 <span class="math display">\[dX=\left[\begin{matrix}dX_{11} &amp; \cdots &amp; dX_{1n}\\\vdots &amp; \ddots &amp;  \\dX_{m1} &amp;  &amp; dX_{mn}\end{matrix}\right]\]</span> <span class="math inline">\(dX\)</span>是与<span class="math inline">\(X\)</span>同形的矩阵，<span class="math inline">\(dX_{ij}\)</span>表示<span class="math inline">\(X_{ij}\)</span>的微分。在<span class="math inline">\(X\)</span>中，每个元素都是一个自变量。令 <span class="math display">\[\frac{\partial f}{\partial X}=\left[\begin{matrix}\frac{\partial{f} }{dX_{11} } &amp; \cdots &amp; \frac{\partial{f}}{dX_{1n} }\\\vdots &amp; \ddots &amp;  \\\frac{\partial{f} }{dX_{m1} } &amp;  &amp; \frac{\partial{f} }{dX_{mn} }\end{matrix}\right]\]</span> 于是 <span class="math display">\[dy=tr(\frac{\partial f}{\partial X}^TdX)\tag{*}\]</span> <span class="math inline">\(tr(X)\)</span> is the trace of<span class="math inline">\(X\)</span>，which stands for the summary ofthe diagonal elements of X. Notice that the <span class="math inline">\(X\)</span> here is a square.</p><h3 id="链式法则">链式法则</h3><ol type="1"><li>若<span class="math inline">\(y=f(Y),Y=AXB+C\)</span>，则根据(*)式：</li></ol><p><span class="math display">\[dy=tr(\frac{\partial f}{\partial Y}^TdY)=tr(\frac{\partial f}{\partialX}^TdX)\]</span></p><p>因为 <span class="math display">\[dY=AdXB\]</span> 则根据性质10： <span class="math display">\[tr(\frac{\partial f}{\partial Y}^TdY)=tr(\frac{\partial f}{\partialY}^TAdXB)=tr(B\frac{\partial f}{\partial Y}^TAdX)=tr(\frac{\partialf}{\partial X}^TdX)\]</span> 于是 <span class="math display">\[\frac{\partial f}{\partial X}^T=B\frac{\partial f}{\partial Y}^TA\\\frac{\partial f}{\partial X}=A^T\frac{\partial f}{\partial Y}B^T\]</span></p><ol start="2" type="1"><li>若<span class="math inline">\(y=f(Y),Y=\sigma(X)\)</span>，其中<span class="math inline">\(\sigma(X)\)</span>为逐元素的函数，因为</li></ol><p><span class="math display">\[dY=\frac{\partial \sigma}{\partial X_{} }\odot dX\]</span></p><p>则根据性质11： <span class="math display">\[tr(\frac{\partial f}{\partial Y}^TdY)=tr(\frac{\partial f}{\partialY}^T(\frac{\partial \sigma}{\partial X_{} }\odot dX))=tr((\frac{\partialf}{\partial Y}^T\odot \frac{\partial \sigma}{\partial X}^T)dX))=tr(\frac{\partial f}{\partial X}^TdX)\]</span> 于是 <span class="math display">\[\frac{\partial f}{\partial X}=\frac{\partial f}{\partial Y}\odot\frac{\partial \sigma}{\partial X }\]</span></p><h2 id="矩阵对矩阵导数未完">矩阵对矩阵导数（未完）</h2><p>​ 首先明确矩阵对矩阵导数的意义。对于<span class="math inline">\(Y_{p\times q}=f(X_{m\times n})\)</span>，函数<span class="math inline">\(f\)</span>将矩阵<span class="math inline">\(X\)</span>映射到另一个形状可能不同的矩阵<span class="math inline">\(Y\)</span>，对于<span class="math inline">\(Y\)</span>的任一元素，<span class="math inline">\(X\)</span>中的全体元素与之存在映射关系。因此，<span class="math inline">\(\frac{dY}{dX}\)</span>应当是一个具有<span class="math inline">\(p\times q \times m\timesn\)</span>个元素的矩阵。矩阵对矩阵求导时将因变量与自变量矩阵向量化，转化为向量对向量导数。向量对向量导数有分子布局与分母布局两种表示方式，这两种表示方式互为转置矩阵。</p><h3 id="分母布局">分母布局</h3><p>​ 本文向量对向量导数采用分母布局，对于<span class="math inline">\(\mathbf{y}=f(\mathbf{x})\)</span>，向量<span class="math inline">\(\mathbf{y}\)</span>对向量<span class="math inline">\(\mathbf{x}\)</span>的导数定义如下： <span class="math display">\[\frac{\partial f}{\partial \mathbf{x} }=\left[\begin{matrix}\frac{\partial{y_1} }{dx_{1} } &amp;\frac{\partial{y_2} }{dx_{1} }&amp;\cdots &amp; \frac{\partial{y_n} }{dx_{1} }\\\frac{\partial{y_1} }{dx_{2} } &amp;\frac{\partial{y_2} }{dx_{2} }&amp;\cdots &amp; \frac{\partial{y_n} }{dx_{2} }\\\vdots &amp; &amp;\ddots &amp;  \\\frac{\partial{y_1} }{dx_{m} } &amp;\frac{\partial{y_2} }{dx_{m} }&amp;\cdots &amp; \frac{\partial{y_n} }{dx_{m} }\\\end{matrix}\right]\]</span></p><h2 id="性质">性质</h2><ol type="1"><li><span class="math inline">\(d(X \pm Y)=d(X)\pm d(Y)\)</span></li><li><span class="math inline">\(d(X_{m \times p}Y_{p\timesn})=(dX)Y+X(dY)\)</span></li></ol><p>​ 证明： <span class="math display">\[d(XY)_{ij}=d(\sum_{i=1}^p{X_{ip}Y_{pj}})=\sum_{i=1}^p(dX_{ip}Y_{pj})+\sum_{i=1}^p(X_{ip}dY_{pj})=(dX)_{i.}Y_{.j}+(dX)_{.i}Y_{j.}\]</span></p><ol start="3" type="1"><li><p><span class="math inline">\(d(X^T)=(dX)^T\)</span></p></li><li><p><span class="math inline">\((dX)^{-1}=-X^{-1}dXX^{-1}\)</span></p></li></ol><p>​ 证明： <span class="math display">\[XX^{-1}=I\\Xd(X^{-1})+(dX)X^{-1}=d(XX^{-1})=d(I)=0\\(dX)^{-1}=-X^{-1}dXX^{-1}\]</span></p><ol start="5" type="1"><li><span class="math inline">\(d(\sigma(X))=\frac{\partial\sigma}{\partial X}\odot dX\)</span></li></ol><p>证明： <span class="math display">\[\begin{aligned}d(\sigma(X))=\left[\begin{matrix}\frac{\partial \sigma}{\partial X_{11}}dX_{11} &amp; \cdots &amp;\frac{\partial \sigma}{\partial X_{1n}}dX_{1n}\\\vdots &amp; \ddots &amp;  \\\frac{\partial \sigma}{\partial X_{m1}}dX_{m1} &amp;  &amp;\frac{\partial \sigma}{\partial X_{mn} }dX_{mn}\end{matrix}\right]= \left[\begin{matrix}\frac{\partial \sigma}{\partial X_{11} } &amp; \cdots &amp;\frac{\partial \sigma}{\partial X_{1n} }\\\vdots &amp; \ddots &amp;  \\\frac{\partial \sigma}{\partial X_{m1} } &amp;  &amp; \frac{\partial\sigma}{\partial X_{mn} }\end{matrix}\right]\odot\left[\begin{matrix}dX_{11} &amp; \cdots &amp;dX_{1n}\\\vdots &amp; \ddots &amp;  \\dX_{m1} &amp;  &amp; dX_{mn}\end{matrix}\right]=\frac{\partial \sigma}{\partial X_{} }\odot dX\end{aligned}\]</span></p><ol start="6" type="1"><li><p><span class="math inline">\(d(X\odot Y)=dX\odot Y+X\odotdY\)</span></p></li><li><p><span class="math inline">\(x\)</span>为标量，或1×1矩阵，<span class="math inline">\(x=tr(x)\)</span></p></li><li><p><span class="math inline">\(tr(X^T)=tr(X)\)</span></p></li><li><p><span class="math inline">\(dtr(X)=tr(dX)\)</span></p></li><li><p><span class="math inline">\(tr(XY)=tr(YX)=tr(X^TY^T)\)</span></p></li><li><p><span class="math inline">\(tr(A^T(B\odot C))=tr((A\odotB)^TC)=tr((A^T\odot B^T)C)\)</span> 可以看到，只有<span class="math inline">\(B\)</span>变成了<span class="math inline">\(B^T\)</span></p></li><li><p><span class="math inline">\(u,v\)</span>是维数相同的向量，<span class="math inline">\(\mathbf 1^T(u\odot v)=u^Tv\)</span></p></li><li><p><span class="math inline">\(u,v\)</span>是维数相同的向量，<span class="math inline">\(u^Tv=v^Tu\)</span></p></li><li><p><span class="math inline">\(vec(A+B)=vec(A)+vec(B)\)</span></p></li><li><p><span class="math inline">\(vec(AXB)=(B^T\otimesA)vec(X)\)</span></p></li></ol><h2 id="示例">示例</h2><p>简便起见，将<span class="math inline">\(\frac{\partial f(a)}{\partiala}\)</span>记为<span class="math inline">\(f&#39;(a)\)</span></p><h3 id="简单单层网络">简单单层网络</h3><p>已知 <span class="math display">\[\hat{y}=XW,\quad X\in R^{1\times m},W\in R^{m\times n}\]</span> 损失函数 <span class="math display">\[L=\frac{1}{2}(\hat{y}-y)({\hat{y}-y)^T }\]</span> <span class="math inline">\(W\)</span>更新公式 <span class="math display">\[W-=lr*\frac{\partial L}{\partial W}\]</span> 为了求<span class="math inline">\(\frac{\partial L}{\partialW}\)</span>，根据(*)式先求<span class="math inline">\(dL\)</span> <span class="math display">\[\begin{aligned}dL&amp;=\frac{1}{2}d((\hat{y}-y))({\hat{y}-y)^T}+\frac{1}{2}(\hat{y}-y)d(({\hat{y}-y)^T) }\\&amp;=\frac{1}{2}(XdW)({\hat{y}-y)^T }+\frac{1}{2}(\hat{y}-y)(XdW)^T \\\end{aligned}\]</span> 注意到<span class="math inline">\((\hat{y}-y)^T\)</span>与<span class="math inline">\(dWX\)</span>均为向量，则根据性质13： <span class="math display">\[dL=(XdW)(\hat{y}-y)^T\tag{1}\]</span> 由于 <span class="math display">\[dL=tr(\frac{\partial f}{\partial W}^TdW)\]</span> 则要将(1)式化为<span class="math inline">\(tr(M^TdW)\)</span>形式，以得出<span class="math inline">\(\frac{\partial L}{\partialW}\)</span>。注意到<span class="math inline">\(dL\)</span>为<span class="math inline">\(1\times1\)</span>方阵，于是 <span class="math display">\[dL=tr(dL)=tr((XdW)(\hat{y}-y)^T)=tr((\hat{y}-y)^TXdW)=tr((X^T(\hat{y}-y))^TdW)\]</span> 因此有 <span class="math display">\[\frac{\partial L}{\partial W}=X^T(\hat{y}-y)\]</span></p><h3 id="单隐藏层网络">单隐藏层网络</h3><p>已知 <span class="math display">\[\hat{y}=g(hW_2+b_2),h=g(XW_1+b_1)\\\quad X\in R^{1\times m},W_1\in R^{m\times n},b_1\in R^{1\timesn},W_2\in R^{n\times q},b_2\in R^{1\times q}\]</span> 损失函数 <span class="math display">\[L=\frac{1}{2}(\hat{y}-y)({\hat{y}-y)^T }\]</span> 参数更新公式 <span class="math display">\[W_1=lr*\frac{\partial L}{\partial W_1},W_2-=lr*\frac{\partialL}{\partial W_2},b_1-=lr*\frac{\partial L}{\partialb_1},b_2-=lr*\frac{\partial L}{\partial b_2}\]</span> 在求某个变量的梯度时，暂且将其他变量视为常量。先求<span class="math inline">\(\frac{\partial L}{\partial b_2}\)</span>，由性质11<span class="math display">\[\begin{aligned}dL&amp;=tr(dL)=tr((g&#39;(hW_2+b_2)\odot db_2)(\hat{y}-y)^T)\\&amp;=tr((\hat{y}-y)(g&#39;(hW_2+b_2)^T\odot db_2^T))\\&amp;=tr(((\hat{y}-y)\odot g&#39;(hW_2+b_2))db_2^T)\\&amp;=tr(((\hat{y}-y)\odot g&#39;(hW_2+b_2))^Tdb_2)\end{aligned}\]</span> 于是 <span class="math display">\[\frac{\partial L}{\partial b_2}=(\hat{y}-y)\odot g&#39;(hW_2+b_2)\]</span> 对于<span class="math inline">\(\frac{\partial L}{\partialW_2}\)</span>： <span class="math display">\[\begin{aligned}dL&amp;=tr(dL)=tr((g&#39;(hW_2+b_2)\odot (hdW_2))(\hat{y}-y)^T)\\&amp;=tr((\hat{y}-y)(g&#39;(hW_2+b_2)^T\odot (hdW_2)^T))\\&amp;=tr(((\hat{y}-y)\odot g&#39;(hW_2+b_2))(hdW_2)^T)\\&amp;=tr(((\hat{y}-y)\odot g&#39;(hW_2+b_2))^ThdW_2)\\&amp;=tr(((h^T((\hat{y}-y)\odot g&#39;(hW_2+b_2)))^TdW_2)\end{aligned}\]</span> 于是 <span class="math display">\[\frac{\partial L}{\partial W_2}=h^T((\hat{y}-y)\odot g&#39;(hW_2+b_2))\]</span> 为求<span class="math inline">\(\frac{\partial L}{\partialb_1}\)</span>，<span class="math inline">\(\frac{\partial L}{\partialW_1}\)</span>，根据链式法则，先求出<span class="math inline">\(\frac{\partial L}{\partial h}\)</span> <span class="math display">\[\begin{aligned}dL&amp;=tr(dL)=tr((g&#39;(hW_2+b_2)\odot (dhW_2))(\hat{y}-y)^T)\\&amp;=tr((\hat{y}-y)(g&#39;(hW_2+b_2)^T\odot (dhW_2)^T))\\&amp;=tr(((\hat{y}-y)\odot g&#39;(hW_2+b_2))(dhW_2)^T)\\&amp;=tr(((\hat{y}-y)\odot g&#39;(hW_2+b_2))^TdhW_2)\\&amp;=tr((((\hat{y}-y)\odot g&#39;(hW_2+b_2))W_2^T)^Tdh)\end{aligned}\]</span> 于是 <span class="math display">\[\frac{\partial L}{\partial h}=((\hat{y}-y)\odot g&#39;(hW_2+b_2))W_2^T\]</span> 设<span class="math inline">\(a=XW_1+b_1\)</span>，则<span class="math inline">\(h=g(a)\)</span>，根据链式法则 <span class="math display">\[\frac{\partial L}{\partial a}=\frac{\partial L}{\partial h}\odot\frac{\partial g}{\partial a}\\\frac{\partial L}{\partial b_1}=\frac{\partial L}{\partial a}\\\frac{\partial L}{\partial W_1}=X^T\frac{\partial L}{\partial a}\]</span> 于是得到 <span class="math display">\[\frac{\partial L}{\partial b_1}=(((\hat{y}-y)\odotg&#39;(hW_2+b_2))W_2^T)\odot \frac{\partial g}{\partial a}\\\frac{\partial L}{\partial W_1}=X^T((((\hat{y}-y)\odotg&#39;(hW_2+b_2))W_2^T)\odot \frac{\partial g}{\partial a})\]</span> ### 经典RNN（未完）</p><p>已知 <span class="math display">\[y_t=f(h_tW_{hy}+b_y)\\h_t=g(x_tW_{xh}+h_{t-1}W_{hh}+b_h)\]</span> 其中<span class="math inline">\(x_t\in R^{1\timesm}\)</span>,<span class="math inline">\(W_{xh}\in R^{m\timesn}\)</span>,<span class="math inline">\(h_t\in R^{1\timesn}\)</span>,<span class="math inline">\(W_{hh}\in R^{n\timesn}\)</span>,<span class="math inline">\(W_{hy}\in R^{n\timesq}\)</span></p><p>注意，<span class="math inline">\(h_t\)</span>为常量。 <span class="math display">\[\begin{aligned}dL&amp;=tr(dL)=tr(dy_t(y-y_t)^T)\\&amp;=tr(f&#39;(h_tW_{hy}+b_y))\end{aligned}\]</span></p><h1 id="特征值与特征向量">特征值与特征向量</h1><p>"There are some matrices for which there are not a full set ofeigenvectors. that's really the main sort of annoying point in the wholesubject of linear algebra is some matrices don't have enougheigenvectors. "</p><p>对于任何一个n阶方阵<span class="math inline">\(A_{n\timesn}\)</span>，它的特征值一定有n个（算上虚特征值和重复特征值），换句话说这等价于实数特征值不超过n个，因为求特征值用<span class="math inline">\(|A-\lambda I|=0\)</span>,最终必定可以化为<span class="math inline">\(\lambda\)</span>的n阶方程，实数解的个数不超过n（代数基本定理）。</p><ul><li>定理1：不同特征值对应的特征向量线性无关。证明：</li></ul><p>设<span class="math inline">\(A\)</span>有两个特征值<span class="math inline">\(\lambda_{1},\lambda_{2}\)</span>和两个对应的特征向量<span class="math inline">\(x_1,x_2\)</span>，且<span class="math inline">\(\lambda_{1}\neq\lambda_{2}\)</span>.假设<span class="math inline">\(x_1,x_2\)</span>线性相关，则<span class="math inline">\(x_1=kx_2\)</span>成立，则<span class="math inline">\(Ax_2=\lambda_2 x_2=Akx_1=kAx_1=k\lambda_1x_1\)</span>,所以(1)当<span class="math inline">\(\lambda_1\ne0\)</span>，有<span class="math inline">\(x_2=\frac{\lambda_1}{\lambda_2}kx_1=kx_1\)</span>,<span class="math inline">\(\lambda_1=\lambda_2\)</span>，矛盾。(2)当<span class="math inline">\(\lambda_1=0\)</span>,因为特征向量非零，所以<span class="math inline">\(\lambda_2=0=\lambda_1\)</span>，矛盾。于是得证</p><h2 id="实数特征值与虚数特征值">实数特征值与虚数特征值</h2><p>从矩阵<span class="math inline">\(A\)</span>的特征值<span class="math inline">\(\lambda\)</span>与特征向量<span class="math inline">\(x\)</span>的计算来看，即<span class="math inline">\(Ax=\lambda x\)</span>，在<span class="math inline">\(x\)</span>方向上，矩阵<span class="math inline">\(A\)</span>只起到了拉伸的作用。若特征值为0，则<span class="math inline">\(A\)</span>将某些向量映射到0空间，这说明<span class="math inline">\(A\)</span>不满秩。若特征值为实数，说明对某些方向上的向量，<span class="math inline">\(A\)</span>仅起到了拉伸的效果，下面将这种矩阵称作拉伸矩阵。若特征值是虚数，说明<span class="math inline">\(A\)</span>对所有方向的向量都起到了旋转的效果，下面将这种矩阵称为旋转矩阵。</p><h3 id="拉伸矩阵">拉伸矩阵</h3><p>对于一个特征向量空间内的向量，拉伸矩阵让一个向量更靠近它最大的特征值对应的特征向量方向。也就是说，在拉伸矩阵的特征向量空间中的向量，一直让它左乘这个拉伸矩阵，那么它最终会逼近最大特征值对应的特征向量方向。为什么要强调是特征向量空间内？因为前面的定理1说明，r个不同特征值可以形成r维特征向量空间，而相同的k重特征值却不一定能形成k维特征向量空间（因为几何重数不大于代数重数，Jordan标准型给出证明）,因此，特征向量空间的维度不一定等于原矩阵的维度（即使原矩阵是满秩的）。因此要强调是特征向量空间内的向量，因为它可以由特征向量表出。</p><p>证明：设矩阵<span class="math inline">\(A_{n\times n}\)</span>有<span class="math inline">\(r\)</span>个不同的特征向量<span class="math inline">\(\lambda_1,...\lambda_r\)</span>，有一个特征向量空间内的向量<span class="math inline">\(x\)</span>,特征向量的基底是<span class="math inline">\(e_1,e_2,...e_r\)</span>,于是 <span class="math display">\[\exists k_1,k_2,...k_n,s.t.\quad x=\sum_{i=1}^rk_ie_i\]</span> 则 <span class="math display">\[\lim_{y\to\infty}A^yx=A^y\sum_{i=1}^rk_ie_i=\sum_{i=1}^rk_iA^ye_i=\sum_{i=1}^rk_i\lambda_i^ye_i\]</span> 容易得知最大的特征值的特征向量方向对结果方向影响最大</p><h3 id="旋转矩阵的分解">旋转矩阵的分解</h3><p>旋转矩阵对所有实数向量都起到了旋转的效果，但也可能起到拉伸效果。事实上，旋转矩阵可以分解成一个纯旋转矩阵和一个拉伸矩阵的矩阵乘积。（<strong>该结论暂未证明</strong>）纯旋转矩阵指的是，左乘纯旋转矩阵只改变向量的方向，而不改变向量的模长。纯旋转矩阵一定是正交矩阵。满足下列关系的矩阵为纯旋转矩阵：<span class="math display">\[\forall \textbf x,k\in[-1,1],cos&lt;\textbf x,A\textbfx&gt;=\frac{\sum_{i=1}^{n}\sum_{j=1}^{n}A_{ij}x_ix_j}{\sum_{i=1}^{n}a_i^2}\equivk\]</span>即旋转矩阵对任意向量的旋转角均相等。这个结论直接计算化简即得。</p><h2 id="相似对角化">相似对角化</h2><p>矩阵<span class="math inline">\(A\)</span>可以相似于对角矩阵<span class="math inline">\(\Lambda\)</span>，当且仅当矩阵<span class="math inline">\(A_{n\timesn}\)</span>有n个线性无关的特征向量。即： <span class="math display">\[\begin{aligned}\Lambda&amp;=P^{-1}AP\\P&amp;=(p_1,p_2,..p_n)\\\Lambda&amp;=\left[\begin{matrix}\lambda_1 &amp;  &amp; \\&amp; \ddots &amp;  \\&amp;  &amp; \lambda_{n}\end{matrix}\right]\end{aligned}\]</span> 其中，<span class="math inline">\(\lambda_i\)</span>对应的特征向量为<span class="math inline">\(p_i\)</span>. 直接计算<span class="math inline">\(AP=P\Lambda\)</span>即可证明。若<span class="math inline">\(A\)</span>相似于对角矩阵，则很容易算<span class="math inline">\(A\)</span>的次方： <span class="math display">\[A^k=P\Lambda^kP^{-1}\]</span></p><h1 id="jordan标准型">Jordan标准型</h1><p>任何n阶方阵可以相似于具有以下形式的矩阵： <span class="math display">\[J_{n\times n}=\left[\begin{matrix}J_1 &amp;  &amp; &amp;\\&amp; J_2&amp; \\  &amp;  &amp; \ddots&amp; \\&amp;  &amp;&amp; J_{k}\end{matrix}\right],J_i=\left[\begin{matrix}\lambda_i &amp;1 &amp; &amp; \\&amp; \lambda_i &amp;1 &amp;  \\  &amp;  &amp;\ddots &amp; \ddots \\&amp; &amp; &amp; \lambda_{i}\end{matrix}\right]\]</span> 其中<span class="math inline">\(\sum_{i=1}^nR(J_i)=n\)</span>.在Gilbert Strang 的 <em>Linear Algebra and Its Applications</em> 中Appendix B 一章通过构造<span class="math inline">\(P\)</span>证明了<span class="math inline">\(\forall A\in R^{n\times n},\exists P,s.t.A=P^{-1}JP\)</span>.</p><p>下面分析Jordan型的意义。</p><p>注意小块最后一行，这一行只有一列，因此，<span class="math inline">\(|J_i-\lambda_i I|=0\)</span>，<span class="math inline">\(\lambda_i\)</span>是<span class="math inline">\(J\)</span>的特征值。</p><p>接下来考虑<span class="math inline">\(J\)</span>的特征向量。对于小块<span class="math inline">\(J_i\)</span>，<span class="math inline">\((J_i-\lambda_iI)x=0\)</span>的解空间维数为1，因此小块<span class="math inline">\(J_i\)</span>对应一个1维特征向量空间。于是容易理解，代数重数大于等于几何重数的原因。每个小块至少是1维，当小块为1维时，这个小块的特征值对应的特征向量空间是1维，此时代数重数等于几何重数。如果小块大于1维，代数重数大于几何重数，这个小块的代数重数等于小块的维数，特征向量空间是1维。相同的特征值可能对应不同的特征向量，此时不同小块中存在相同的特征值，而这些不同的小块对应不同的特征向量。</p><h1 id="变换">变换</h1><p>矩阵乘向量在几何意义上就是向量的线性变换，满秩矩阵把这个向量映射到同维空间的另一个向量，不满秩矩阵把它映射到低维空间的另一个向量。矩阵乘矩阵在几何意义上是基底变换，一个矩阵的每一列视为一个基底向量，基底变换就是把一组基底映射到另一组基底，满秩矩阵把基底映射到同维空间的另一组基底，不满秩矩阵把基底映射到低维空间的另一组基底。</p><h2 id="基底变换">基底变换</h2><p>一个可逆矩阵可以将一组基底变换到在同维空间中的任意一组基底。这其实就是矩阵乘的意义。设有一组基底<span class="math inline">\((e_1,e_2,...e_n)\)</span>，他们构成矩阵<span class="math inline">\(M\)</span>，其中<span class="math inline">\(e_i\)</span>是<span class="math inline">\(n\times1\)</span>列向量，对于n维空间中任意一组基底构成的矩阵<span class="math inline">\(N\)</span>，设经过左乘矩阵<span class="math inline">\(P\)</span>从<span class="math inline">\(M\)</span>变换到<span class="math inline">\(N\)</span>，则 <span class="math display">\[\begin{aligned}N&amp;=MP\\P&amp;=M^{-1}N\end{aligned}\]</span> 于是可知存在唯一的矩阵<span class="math inline">\(P\)</span>使得基底<span class="math inline">\(M\)</span>变换到基底<span class="math inline">\(N\)</span></p><p>基底变换定理：基底变换不改变向量本身，通过基底变换变的是向量在这组基底下的各个分量的取值。也就是说，在标准正交基下（或者任何一组作为参考的基底）的向量是不变的。基底<span class="math inline">\(M\)</span>经过基底变换得到基底<span class="math inline">\(N\)</span>，即有<span class="math inline">\(N=MP\)</span>，对同一个标准正交基下的向量<span class="math inline">\(\textbf x\)</span>，其在<span class="math inline">\(M,N\)</span>下的分量为<span class="math inline">\(\alpha,\alpha&#39;\)</span>，即有<span class="math inline">\(M\alpha=N\alpha&#39;=\textbfx,\alpha&#39;=P^{-1}\alpha\)</span></p><p>从这个结论来看，向量的线性变换的意义可以归结为以下两个等价的观点：</p><p>1）在基底不变的情况下，<span class="math inline">\(\textbfx\)</span>变换到同基底下的<span class="math inline">\(P\textbfx\)</span></p><p>2）在向量不变的情况下，基底<span class="math inline">\(M\)</span>变换到<span class="math inline">\(PM\)</span>，<span class="math inline">\(\textbfx\)</span>在新基底<span class="math inline">\(PM\)</span>下的分量为<span class="math inline">\(P^{-1}\textbf x\)</span></p><p>这两种观点是等价的，区别只在于选择向量还是基底作为参考，而用两种观点来描述的他们之间的相对关系是一样的。基底不变，向量变等价于向量不变，基底变。</p><h2 id="相似变换">相似变换</h2><p>基底<span class="math inline">\(M\)</span>经过基底变换得到基底<span class="math inline">\(N\)</span>，即有<span class="math inline">\(N=MP\)</span>，对同一个标准正交基下的向量<span class="math inline">\(\textbf x\)</span>，其在<span class="math inline">\(M,N\)</span>下为<span class="math inline">\(\alpha,\alpha&#39;\)</span>，即有<span class="math inline">\(M\alpha=N\alpha&#39;=\textbfx,\alpha&#39;=P^{-1}\alpha\)</span>，<span class="math inline">\(\alpha\)</span>经过线性变换得到向量<span class="math inline">\(\beta\)</span>，即<span class="math inline">\(\beta=A\alpha\)</span>，设<span class="math inline">\(\beta\)</span>在<span class="math inline">\(N\)</span>下为<span class="math inline">\(\beta&#39;\)</span>，于是有<span class="math inline">\(\beta&#39;=P^{-1}\beta\)</span>，设矩阵<span class="math inline">\(A&#39;\)</span>使得<span class="math inline">\(\beta&#39;=A&#39;\alpha&#39;\)</span>，于是 <span class="math display">\[\beta&#39;=A&#39;\alpha&#39;=P^{-1}\beta=P^{-1}A\alpha=P^{-1}AP\alpha&#39;\]</span> 则 <span class="math display">\[A&#39;=P^{-1}AP\tag{2}\]</span>上面的结论说明，一个向量被映射到另一个向量，在两个不同的基底下的两个变换关系之间具有(2)式描述的关系。因此，相似变换是同一个线性变换在不同基底下的不同表现形式。</p><h3 id="相似对角化-1">相似对角化</h3><p>若方阵经相似变换能化为对角矩阵，则这个方阵可相似对角化。</p><p><span class="math inline">\(A_{n\times n}\)</span>可相似对角化<span class="math inline">\(\iff\)</span><span class="math inline">\(A_{n\times n}\)</span>有n个线性无关的特征向量</p><p>证明：充分性：若<span class="math inline">\(A_{n\timesn}\)</span>可相似对角化，设其相似于对角矩阵<span class="math inline">\(B=diag(b_1,b_2,...b_n)\)</span>，且<span class="math inline">\(B=P^{-1}AP\)</span>，则<span class="math inline">\(PB=AP\)</span>. 将<span class="math inline">\(P\)</span>以列向量形式表示，<span class="math inline">\(P={p_{.1},p_{.2},...p_{.n})\)</span> . 因为 <span class="math display">\[PB=(p_{.1},p_{.2},...p_{.n})\]</span> 从几何角度考虑，相似对角化实质上是把原矩阵<span class="math inline">\(A\)</span>对应的基底变换到特征向量方向上，这时新的基底两两正交。</p><h2 id="合同变换">合同变换</h2><p>任意一个二次型 <span class="math display">\[f(\textbf x)=\sum_{i=1}^n\sum_{j=1}^{n} k_{ij}x_ix_j,\textbfx=(x_1,x_2,...x_n)^T\]</span> 均可以化为矩阵乘形式<span class="math inline">\(\textbfx^TA\textbf x\)</span>，可以证明这样的<span class="math inline">\(A\)</span>有无数个。当<span class="math inline">\(A\)</span>为对称矩阵，则<span class="math inline">\(A\)</span>是唯一的，此时有 <span class="math display">\[a_{ij}=\left\{\begin{array}{l}\frac{k_{ij}+k_{ji} }{2},\quad i\neq j \\k_{ij},\quad i=j \\\end{array}\right.\]</span> 当对基底<span class="math inline">\(M\)</span>下的向量<span class="math inline">\(\textbf x\)</span>进行线性变换<span class="math inline">\(C^{-1}\)</span>(为了让结论形式看起来简洁，写成C的逆矩阵。其实只要这里是个可逆矩阵就行)，得到另一个基底<span class="math inline">\(N\)</span>下的向量<span class="math inline">\(\textbf y\)</span>，即<span class="math inline">\(\textbf x=C\textbf y\)</span>，这时<span class="math inline">\(f(\textbf x)=g(\textbf y)=\textbf x^TA\textbfx=\textbf y^TC^TAC\textbf y=\textbf y^TA&#39;\textbf y\)</span>，于是<span class="math display">\[A&#39;=C^TAC\]</span>上面的结论说明，同一个二次型在两个不同的基底下，两个变换关系之间具有(2)式描述的关系。</p><h3 id="惯性定理">惯性定理</h3><p>上面说到，合同变换可以视为同一个二次型在两个不同的基底下的不同的描述形式，因此，我们可以通过变换基底，让二次型只含有平方项，不含有<span class="math inline">\(x_1x_2\)</span>这种混合乘积，并且平方项系数只能为0，1，-1，也就是化成标准型。可以想象，一定存在某一个位置可以达到这种效果，例如一个椭圆，两个基底向量分别它的长轴和短轴重合时，就只含有平方项，将长轴一半和短轴一半长度作为两个基底向量的单位长度，就得到标准型，变成了一个单位圆。事实上，将任意二次型化成标准型存在且只存在一种合同变换。下面证明这个结论。</p><p>证明：设有二次型<span class="math inline">\(f(\textbf x)=g(\textbfy)=\textbf x^TA\textbf x=\textbf y^T B\textbf y\)</span>，其中<span class="math inline">\(B\)</span>为对角矩阵。若证明了<span class="math inline">\(B\)</span>是对角矩阵，则可将<span class="math inline">\(B\)</span>化为只含0，1，-1的对角矩阵。于是原命题等价于证存在<span class="math inline">\(C\)</span>满足<span class="math inline">\(B=C^TAC\)</span>.</p><p>因为<span class="math inline">\(A\)</span>为对称矩阵，根据对称矩阵的结论，存在正交矩阵<span class="math inline">\(P\)</span>使得<span class="math inline">\(A=P^{-1}B P\)</span>，根据正交矩阵的结论，<span class="math inline">\(P^{-1}=P^T\)</span>，于是<span class="math inline">\(B=PAP^T\)</span>，即证</p><p>标准型中正、负号的个数称为正、负惯性系数。因为合同变换是同一个二次型在不同基底下的形式，而将任意二次型化成标准型存在且只存在一种合同变换，因此易知合同变换不改变正负惯性系数。</p><h2 id="正交化">正交化</h2><h3 id="向量投影">向量投影</h3><p>向量<span class="math inline">\(\alpha\)</span>在一组标准正交基<span class="math inline">\(V=(\beta_1,\beta_2,...\beta_m)\)</span>下的投影为<span class="math display">\[proj_V\alpha=\sum_{i=1}^m(\alpha\cdot\beta_i)\beta_i\]</span> 其中，<span class="math inline">\(\alpha,\beta_i\)</span>均为n维向量（<span class="math inline">\(n\ge m\)</span>），<span class="math inline">\(\alpha\cdot\beta_i\)</span>是<span class="math inline">\(\alpha\)</span>在<span class="math inline">\(\beta_i\)</span>方向上投影的向量长度。当<span class="math inline">\(n=m\)</span>时，<span class="math inline">\(\alpha\)</span>可由<span class="math inline">\(V\)</span>线性表出，此时<span class="math inline">\(\alpha=proj_V\alpha\)</span>，当<span class="math inline">\(n&gt; m\)</span>，<span class="math inline">\(\alpha_p=\alpha-proj_V\alpha\)</span>与空间<span class="math inline">\(V\)</span>垂直。这里与空间垂直的意义是，<span class="math inline">\(\alpha_p\)</span>与每个基向量垂直。向量与线和平面垂直的情况容易想象。从想象中可以得到以下定理（<strong>该结论暂未证明</strong>）：所有<span class="math inline">\(\alpha\)</span>对应的<span class="math inline">\(\alpha_p\)</span>形成的向量空间的维度=m-n.</p><h3 id="正交化-1">正交化</h3><p>任意线性无关的一组向量均可以化为该向量空间下的一组标准正交基。</p><p>根据投影定义可以知道，任何一个与向量空间<span class="math inline">\(V\)</span>中所有基向量线性无关的向量<span class="math inline">\(\alpha\)</span>均能表示成这个空间内的投影<span class="math inline">\(proj_V\alpha\)</span>+与这个空间垂直的向量<span class="math inline">\(\alpha_p\)</span>.因此，可以采用如下方法得到一组基<span class="math inline">\((\beta_1,\beta_2,...\beta_m)\)</span>的标准正交基：</p><p>1）取第一个向量<span class="math inline">\(\beta_1\)</span>，将其归一化，加入到子空间<span class="math inline">\(W\)</span>中</p><p>2）取第k(k&gt;1)个向量<span class="math inline">\(\beta_k\)</span>，计算其与子空间<span class="math inline">\(W\)</span>垂直的向量<span class="math inline">\(\beta_{kp}=\beta-proj_V\beta_{k}\)</span>，并将<span class="math inline">\(\beta_{kp}\)</span>归一化，加入到<span class="math inline">\(W\)</span>中</p><p>3）重复2），直到k=n</p><h3 id="正交向量空间">正交向量空间</h3><p>若k维空间<span class="math inline">\(V\)</span>中的一组基<span class="math inline">\((\alpha_1,...\alpha_k)\)</span>与另一r维空间<span class="math inline">\(W\)</span>中的一组基<span class="math inline">\((\beta_1,...\beta_r)\)</span>正交(<span class="math inline">\(\alpha_i,\beta_j\)</span>为同维向量)，则空间<span class="math inline">\(V\)</span>与空间<span class="math inline">\(W\)</span>中所有向量均正交。</p><p>证明：设<span class="math inline">\(V\)</span>中一向量<span class="math inline">\(\alpha=\sum_{i=1}^{k}m_i\alpha_i\)</span>,<span class="math inline">\(W\)</span>中一向量<span class="math inline">\(\beta=\sum_{i=1}^{r}n_i\beta_i\)</span>, 则 <span class="math display">\[\alpha \cdot\beta=(\sum_{i=1}^{k}m_i\alpha_i)(\sum_{i=1}^{r}n_i\beta_i)=\sum_{i=1}^{k}\sum_{j=1}^r(m_in_j\alpha_i\cdot\beta_j)=0\]</span> 于是两空间中任意向量均正交。</p><p>#特殊矩阵</p><h2 id="正交矩阵">正交矩阵</h2><ul><li>正交矩阵满足<span class="math inline">\(A^{-1}=A^T\)</span></li></ul><p>将矩阵写成列向量形式<span class="math inline">\(A=(a_1,a_2,...a_n)\)</span>，若 <span class="math display">\[a_i\cdot a_{j}=\left\{\begin{array}{l}0,\quad i\neq j \\1,\quad i=j \\\end{array}\right.\]</span> 则<span class="math inline">\(A\)</span>为正交矩阵。</p><p>若<span class="math inline">\(A\)</span>为正交矩阵，则<span class="math inline">\(A^TA=I\)</span>，因为 <span class="math display">\[A^TA=\left(\begin{matrix}a_1^T \\a_2^T    \\...\\a_n^T\end{matrix}\right)(a_1,a_2,...a_n)=\left(\begin{matrix}a_1^Ta_1 &amp;a_1^Ta_2 &amp;...  \\a_2^Ta_1 &amp; \ddots &amp;  \\...&amp;  &amp; a_n^Ta_n\end{matrix}\right)=I\]</span> 于是可得<span class="math inline">\(A^{-1}=A^T\)</span></p><h2 id="对称矩阵">对称矩阵</h2><ul><li>任何一个矩阵 A可以表示为一个反对称矩阵M + 一个对称矩阵S</li></ul><p>证明：如果原命题成立，只要证明存在这样的<span class="math inline">\(M\)</span>和<span class="math inline">\(N\)</span>，因为 <span class="math display">\[\begin{aligned}A_{ij}&amp;=M_{ij}+S_{ij}\\A_{ji}&amp;=M_{ji}+S_{ji}=-M_{ji}+S_{ij}\end{aligned}\]</span> 两个未知数<span class="math inline">\(A_{ij},A_{ji}\)</span>两个等式可以解出两个未知数<span class="math inline">\(M_{ij},S_{ij}\)</span>，即证</p><ul><li>矩阵<span class="math inline">\(A\)</span>是实对称矩阵<span class="math inline">\(\iff\)</span><span class="math inline">\(A=P^{-1}\Lambda P\)</span>，<span class="math inline">\(\Lambda\)</span>是对角矩阵，<span class="math inline">\(P\)</span>是正交矩阵</li></ul><p>证明：1）充分性：若<span class="math inline">\(A\)</span>为实对称矩阵，设<span class="math inline">\(J=P^{-1}AP\)</span>, <span class="math inline">\(J\)</span>为Jordan矩阵。假设<span class="math inline">\(A\)</span>不可对角化，则<span class="math inline">\(J\)</span>存在维数大于1的小块。不妨设<span class="math inline">\(J_1\)</span>维数大于1，即 <span class="math display">\[J_1=\left[\begin{matrix}\lambda_1 &amp;1 &amp; &amp; \\&amp; \lambda_1 &amp;\ddots &amp;  \\  &amp;  &amp;\ddots &amp;  \\\end{matrix}\right]\]</span> 令<span class="math inline">\(B=P^TP\)</span>，则<span class="math inline">\(B\)</span>为对称矩阵，<span class="math inline">\(b_{12}=b_{21}\)</span>，且<span class="math inline">\(b_{11}=\sum_{i=1}^{n}p_{i1}^2\)</span>，因为<span class="math inline">\(P\)</span>可逆，所以<span class="math inline">\(p_{i1}\)</span>不全为0，<span class="math inline">\(b_{11}&gt;0\)</span>. 因为<span class="math inline">\(P^TAP=P^TPJ=BJ\)</span>, <span class="math inline">\(PAP^T\)</span>为对称矩阵，则<span class="math inline">\(BJ\)</span>为对称矩阵。因为<span class="math inline">\(BJ\)</span>第1行第2列元素为<span class="math inline">\(b_{11}+\lambda_1b_{12}\)</span>，第2行第1列元素为<span class="math inline">\(\lambda_1b_{21}\)</span>，则<span class="math inline">\(BJ\)</span>为非对称矩阵，矛盾。因此<span class="math inline">\(A\)</span>可对角化。</p><p>下面证明实对称矩阵<span class="math inline">\(A\)</span>不同特征值对应的特征向量之间相互正交。</p><p>设<span class="math inline">\(\alpha_1,\alpha_2\)</span>是<span class="math inline">\(A\)</span>的两个不同的特征向量，<span class="math inline">\(A\alpha_1=\lambda_1\alpha_1,A\alpha_2=\lambda_2\alpha_2\)</span>,且<span class="math inline">\(\lambda_2\ne\lambda_1\)</span>,分别左乘<span class="math inline">\(\alpha_2^T,\alpha_1^T\)</span>,则<span class="math inline">\(\alpha_2^TA\alpha_1=\lambda_1\alpha_2^T\alpha_1,\alpha_1^TA\alpha_2=\lambda_2\alpha_1^T\alpha_2\)</span>,因为向量数乘可交换，所以<span class="math inline">\(\alpha_2^TA\alpha_1=(A\alpha_2)^T\alpha_1=\alpha_1^T(A\alpha_2)=\alpha_1^TA\alpha_2\)</span>,于是<span class="math inline">\(\lambda_2\alpha_1^T\alpha_2=\lambda_1\alpha_2^T\alpha_1\)</span>,<span class="math inline">\((\lambda_2-\lambda_1)\alpha_1^T\alpha_2=0\)</span>,则<span class="math inline">\(\alpha_1^T\alpha_2=0\)</span>.</p><p>因此<span class="math inline">\(A\)</span>的不同特征值对应的特征向量构成正交向量空间，在每个r维特征向量空间中选取r个线性无关的模长为1的向量，按列构成矩阵<span class="math inline">\(P\)</span>即可。</p><p>2）必要性：若<span class="math inline">\(A=P^{-1}\LambdaP\)</span>，<span class="math inline">\(\Lambda\)</span>是对角矩阵，<span class="math inline">\(P\)</span>是正交矩阵，则<span class="math inline">\(P^{-1}=P^T,A=P^T\LambdaP,A^T=P^T\Lambda^TP=P^T\Lambda P=A\)</span>, 则<span class="math inline">\(A\)</span>为对称矩阵。下面证明<span class="math inline">\(A\)</span>的特征值均为实数。</p><p>设<span class="math inline">\(Ax=\lambda x\)</span>, <span class="math inline">\(\lambda=a+bi\)</span>, <span class="math inline">\(\bar{x}^TAx=\lambda \bar{x}^Tx\)</span>,直接计算可证<span class="math inline">\(\bar{AB}=\bar{A}\bar{B}\)</span>, 因此<span class="math inline">\(\bar{x}^TAx=\bar{x}^T\bar{A}^Tx=(\bar{Ax})^Tx=\lambda\bar{x}^Tx\)</span>, 于是<span class="math inline">\(\bar{Ax}=\lambda\bar{x}\)</span>, 则<span class="math inline">\(Ax=\bar{\lambda}x\)</span>, 则<span class="math inline">\(b=0\)</span>. 因此<span class="math inline">\(A\)</span>所有特征值为实数。</p><h2 id="正定矩阵">正定矩阵</h2><p>若实对称矩阵所有特征值均&gt;0,则为正定，若均<span class="math inline">\(\ge0\)</span>,则为半正定，均&lt;0为负定矩阵。</p><p>从几何意义考虑，一个正定矩阵<span class="math inline">\(A_{n\timesn}\)</span>满足<span class="math inline">\(\forall x\in R^{n\times1},x^TAx&gt;0\)</span>，这表明向量<span class="math inline">\(x\)</span>与<span class="math inline">\(Ax\)</span>的内积为正，对于二，三维向量就是夹角小于<span class="math inline">\(\frac{\pi}{2}\)</span>，高维向量也类比这个方式理解。</p>]]></content>
    
    
    <categories>
      
      <category>Math</category>
      
      <category>Matrix</category>
      
    </categories>
    
    
    <tags>
      
      <tag>matrix</tag>
      
      <tag>math</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Exploring the Performance of ML Models for Low Dimensional Dataset with a Large Number of Samples</title>
    <link href="/2023/04/21/Low-Dimensional-Data-with-a-Large-Number-of-Samples/"/>
    <url>/2023/04/21/Low-Dimensional-Data-with-a-Large-Number-of-Samples/</url>
    
    <content type="html"><![CDATA[<h2 id="brief-introduction">Brief introduction</h2><p>​ In this article I will use a low dimensional dataset with a largenumber of samples which has 13404 rows and 3 columns. It records theluminousness of different kind of seeds under different luminousintensity. The first column records luminous intensity which is in therange of 650 to 4000. The second column records the luminousness of theseed. The third column is the class of the seeds which has a totalnumber of 4 classes.</p><span id="more"></span><h2 id="models">Models</h2><p>​ Use 5 models, Support vector machine(SVM), K nearest neighbors(KNN),Deep neural network(DNN), Decision Tree(DT) and Random Forest(RF) thatwere implemented based on sklearn. The parameters' setting is asfollowing:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">SVM = svm.SVC(C=<span class="hljs-number">1</span>, random_state=<span class="hljs-number">42</span>)<br>KNN = KNeighborsClassifier(n_neighbors=<span class="hljs-number">5</span>)<br>DNN = MLPClassifier(hidden_layer_sizes=(<span class="hljs-number">50</span>,<span class="hljs-number">50</span>,<span class="hljs-number">50</span>,<span class="hljs-number">50</span>),alpha=<span class="hljs-number">0.001</span>, max_iter=<span class="hljs-number">1000</span>)<br>DT = DecisionTreeClassifier(criterion=<span class="hljs-string">&#x27;entropy&#x27;</span>,max_depth=<span class="hljs-number">10</span>,min_samples_leaf=<span class="hljs-number">3</span>)<br>RF = RandomForestClassifier(criterion=<span class="hljs-string">&#x27;entropy&#x27;</span>,max_depth=<span class="hljs-number">10</span>,n_estimators=<span class="hljs-number">30</span>,min_samples_leaf=<span class="hljs-number">5</span>)<br></code></pre></td></tr></table></figure><h2 id="result">Result</h2><h3 id="evaluation-metrics">Evaluation metrics</h3><p>​ Accuracy, precision and recall are used as evaluation metrics. Theresult is shown as following:</p><p><img src="result.PNG"></p><h3 id="confusion-matrix">Confusion matrix</h3><p><img src="DNN.png"><img src="DT.png" width="300" height="200"></p><h3 id="conclusion">Conclusion</h3><p>​ On this dataset, KNN achieved the best performance, while SVMperformed the worst. It seems KNN is suitable for low-dimensional datawith a large number of samples. To some extent, in high-dimensionaldatasets, samples from different classes may have more similar features,which is not beneficial for KNN.</p><p>Code:https://github.com/qdhdusdc/Exploring-Low-Dimensional-Data/tree/main</p>]]></content>
    
    
    <categories>
      
      <category>ML</category>
      
      <category>Traditional</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Machine Learning</tag>
      
      <tag>Exploring</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Euler&#39;s Formula</title>
    <link href="/2023/04/06/Euler-s-Formula/"/>
    <url>/2023/04/06/Euler-s-Formula/</url>
    
    <content type="html"><![CDATA[<hr><span id="more"></span><h1 id="eulers-formula">Euler's Formula</h1><h2 id="transition">Transition</h2><p>​ It is known the natural logarithm can be defined as: <span class="math display">\[e=\displaystyle\lim_{ x \to \infty}(1+\frac{ 1}{ x})^x\]</span> ​ If we want to popularize it to imaginary, one form ismeaningful: <span class="math display">\[f(e)=\displaystyle\lim_{x \to \infty}(1+\frac{i}{x})^x\]</span> ​ I use <span class="math inline">\(\mit f\)</span><span class="math inline">\((e)\)</span> to stand the result we get. It is animaginary number, in other words it can be expressed as: <span class="math display">\[f(e)=a+bi\]</span> ​ It is worth noting that <span class="math inline">\(f\)</span><span class="math inline">\((e)\)</span>has another form, actually every power of e has this property. <span class="math display">\[\displaystyle\lim_{x \to \infty}(1+\frac{i}{x})^x=\displaystyle\lim_{x\to \infty}((1+\frac{i}{x})^{\frac{x}{i} })^i=e^i=a+bi\]</span> ​ It seems just a trick of mathematic manipulation. However, itbring us a lot convenience in the future steps. We will see its powersoon.</p><p>​ The next goal is to find the <span class="math inline">\(\mit{a}\)</span> and <span class="math inline">\(\mit{b}\)</span>. To achieve this, we should knowsome interesting property and mathematic meaning of the imaginarynumber.</p><p>##Imaginary number and rotary</p><p>​ Frankly speaking I had been confused by imaginary number for a longtime, until I got it can solve rotary problems one day. Let's see anexample, suppose we have two imaginary number <span class="math inline">\({\mit{a} }=r_1(cos\alpha_{1}+{\mit{i}}sin\beta_{1})\)</span> and <span class="math inline">\({\mit{b}}=r_2(cos\alpha_{2}+{\mit{i}}sin\beta_{2})\)</span> , then consider the multiplication of <span class="math inline">\(\mit{a}\)</span> and <span class="math inline">\(b\)</span>: <span class="math display">\[\begin{aligned}a\timesb&amp;=r_1r_2(cos\alpha_{1}cos\alpha_{2}-sin\alpha_{1}sin\alpha_{2}+{\mit{i}}   (cos\alpha_1sin\alpha_2+cos\alpha_2sin\alpha_1))\\&amp;= r_1r_2(cos(\alpha_1+\alpha_2)+isin(\alpha_1+\alpha_2))\end{aligned}\]</span> ​ Look, the multiplication of <span class="math inline">\(\mit{a}\)</span> and <span class="math inline">\(\mit{b}\)</span> results to a new imaginarynumber, whose argument is the sum of that of <span class="math inline">\(\mit{a}\)</span> and <span class="math inline">\(\mit{b}\)</span> and the length is themultiplication of that of <span class="math inline">\(\mit{a}\)</span>and <span class="math inline">\(\mit{b}\)</span>. In fact, this propertycan be popularized to the multiplication of <span class="math inline">\(\mit{n}\)</span> imaginary numbers or an imaginaryto the power of <span class="math inline">\(n\)</span>, as following:<span class="math display">\[\begin{aligned}a^n&amp;=(r(cos\alpha+isin\alpha))^n=r^n(cos(n\alpha)+isin(n\alpha))\quad(n\inR)\end{aligned}\]</span></p><p>​ It will help us in the next step.</p><p>##When comes to infinite</p><p>​ It is said above <span class="math inline">\(e^i=\displaystyle\lim_{x \to\infty}(1+\frac{i}{x})^x\)</span> is an imaginary number, so we need toconsider two aspects of it: argument and length. It is themultiplication of many <span class="math inline">\((1+\frac{i}{x})\)</span>s. Let me give it a name,called <span class="math inline">\({\mit{I}}\)</span> (Just think it isan individual of the big population). Then the argument of <span class="math inline">\(e^i\)</span> will be: <span class="math display">\[arg(e^i)=x\times arg(I)\quad(x \to \infty)\]</span> And the tangent of the argument of <span class="math inline">\(\mit{i}\)</span> is: <span class="math display">\[tan(arg(I))=\frac{1}{x}\quad(x \to \infty)\]</span> So we can get the argument of <span class="math inline">\(e^i\)</span> : <span class="math display">\[\displaystyle\lim_{x \to \infty}arg(e^i)=\displaystyle\lim_{x \to\infty}x\times arctan\frac{1}{x}=\displaystyle\lim_{t \to0}\frac{arctan\,t}{t}=1\]</span> This transformation can be derived by L'Hôpital's rule. Thenconsider the length of <span class="math inline">\(e^i\)</span>: <span class="math display">\[L(e^i)=L(I)^x\quad(x\to \infty)\]</span> And the length of <span class="math inline">\(I\)</span> is:<span class="math display">\[L(I)=\sqrt{1+\frac{1}{x^2} }\quad(x\to\infty)\]</span> So we can get the length of <span class="math inline">\(e^i\)</span>: <span class="math display">\[L(e^i)=\displaystyle\lim_{x \to \infty}({\sqrt{1+\frac{1}{x^2} }})^x=\displaystyle\lim_{x \to \infty}({ {1+\frac{1}{x^2} }})^{\frac{x}{2} }=\displaystyle\lim_{x \to \infty}(({ {1+\frac{1}{x^2} }})^{ {x^2} })^\frac{1}{2x}=\displaystyle\lim_{x \to\infty}e^{\frac{1}{2x} }=1\]</span> The argument and the length of <span class="math inline">\(e^i\)</span> are both 1, so <span class="math inline">\(e^i=cos1+isin1\)</span>. Then we can deriveEuler's formula: <span class="math display">\[e^{i\theta}=(e^i)^\theta=(cos1+isin1)^\theta=cos\theta+isin\theta\]</span></p>]]></content>
    
    
    <categories>
      
      <category>Math</category>
      
      <category>Calculus</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Math</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>爬和撞</title>
    <link href="/2023/04/01/%E7%88%AC%E5%92%8C%E6%92%9E/"/>
    <url>/2023/04/01/%E7%88%AC%E5%92%8C%E6%92%9E/</url>
    
    <content type="html"><![CDATA[<p>​从前梁实秋教授曾经说过：穷人总是要爬，往上爬，爬到富翁的地位。不但穷人，奴隶也是要爬的，有了爬得上的机会，连奴隶也会觉得自己是神仙，天下自然太平了。</p><p>​虽然爬得上的很少，然而个个以为这正是他自己。这样自然都安分的去耕田，种地，拣大粪或是坐冷板凳，克勤克俭，背着苦恼的命运，和自然奋斗着，拚命的爬，爬，爬。可是爬的人那么多，而路只有一条，十分拥挤。老实的照着章程规规矩矩的爬，大都是爬不上去的。聪明人就会推，把别人推开，推倒，踏在脚底下，踹着他们的肩膀和头顶，爬上去了。大多数人却还只是爬，认定自己的冤家并不在上面，而只在旁边——是那些一同在爬的人。他们大都忍耐着一切，两脚两手都着地，一步步的挨上去又挤下来，挤下来又挨上去，没有休止的。</p><span id="more"></span><p>​然而爬的人太多，爬得上的太少，失望也会渐渐的侵蚀善良的人心，至少，也会发生跪着的革命。于是爬之外，又发明了撞。</p><p>​这是明知道你太辛苦了，想从地上站起来，所以在你的背后猛然的叫一声：撞罢。一个个发麻的腿还在抖着，就撞过去。这比爬要轻松得多，手也不必用力，膝盖也不必移动，只要横着身子，晃一晃，就撞过去。撞得好就是五十万元大洋，妻，财，子，禄都有了。撞不好，至多不过跌一交，倒在地下。那又算得什么呢，——他原本是伏在地上的，他仍旧可以爬。何况有些人不过撞着玩罢了，根本就不怕跌交的。</p><p>​爬是自古有之。例如从童生到状元，从小瘪三到康白度。撞却似乎是近代的发明。要考据起来，恐怕只有古时候“小姐抛彩球”有点像给人撞的办法。小姐的彩球将要抛下来的时候，——一个个想吃天鹅肉的男子汉仰着头，张着嘴，馋涎拖得几尺长……可惜，古人究竟呆笨，没有要这些男子汉拿出几个本钱来，否则，也一定可以收着几万万的。</p><p>​爬得上的机会越少，愿意撞的人就越多，那些早已爬在上面的人们，就天天替你们制造撞的机会，叫你们化些小本钱，而豫约着你们名利双收的神仙生活。所以撞得好的机会，虽然比爬得上的还要少得多，而大家都愿意来试试的。这样，爬了来撞，撞不着再爬……鞠躬尽瘁，死而后已。</p>]]></content>
    
    
    <categories>
      
      <category>文学</category>
      
      <category>杂文</category>
      
    </categories>
    
    
    <tags>
      
      <tag>鲁迅</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
